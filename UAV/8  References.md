# References

1. Liu et al. [2024]Y. Liu, F. Yao, Y. Yue, G. Xu, X. Sun, K. Fu,Navagent: Multi-scale urban street view fusion for uav embodied vision-and-language navigation,arXiv preprint arXiv:2411.08579 (2024).
2. Sarkar et al. [2024]A. Sarkar, S. Sastry, A. Pirinen, C. Zhang, N. Jacobs, Y. Vorobeychik,Gomaa-geo: Goal modality agnostic active geo-localization,arXiv preprint arXiv:2406.01917 (2024).
3. Liu et al. [2024]J. Liu, J. Cui, M. Ye, X. Zhu, S. Tang,Shooting condition insensitive unmanned aerial vehicle object detection,Expert Systems with Applications 246 (2024) 123221.
4. Qiu et al. [2024]H. Qiu, J. Li, J. Gan, S. Zheng, L. Yan,Dronegpt: Zero-shot video question answering for drones,in: Proceedings of the International Conference on Computer Vision and Deep Learning, 2024, pp. 1–6.
5. Chen et al. [2023]G. Chen, X. Yu, N. Ling, L. Zhong,Typefly: Flying drones with large language model,arXiv preprint arXiv:2312.14950 (2023).
6. Tagliabue et al. [2023]A. Tagliabue, K. Kondo, T. Zhao, M. Peterson, C. T. Tewari, J. P. How,Real: Resilience and adaptation using large language models on autonomous aerial robots,arXiv preprint arXiv:2311.01403 (2023).
7. Panagiotou and Yakinthos [2020]P. Panagiotou, K. Yakinthos,Aerodynamic efficiency and performance enhancement of fixed-wing uavs,Aerospace Science and Technology 99 (2020) 105575.
8. Villa et al. [2020]D. K. Villa, A. S. Brandao, M. Sarcinelli-Filho,A survey on load transportation using multirotor uavs,Journal of Intelligent & Robotic Systems 98 (2020) 267–296.
9. Rashad et al. [2020]R. Rashad, J. Goerres, R. Aarts, J. B. Engelen, S. Stramigioli,Fully actuated multirotor uavs: A literature review,IEEE Robotics & Automation Magazine 27 (2020) 97–107.
10. Alvarenga et al. [2015]J. Alvarenga, N. I. Vitzilaios, K. P. Valavanis, M. J. Rutherford,Survey of unmanned helicopter model-based navigation and control techniques,Journal of Intelligent & Robotic Systems 80 (2015) 87–138.
11. Saeed et al. [2018]A. S. Saeed, A. B. Younes, C. Cai, G. Cai,A survey of hybrid unmanned aerial vehicles,Progress in Aerospace Sciences 98 (2018) 91–105.
12. Du et al. [2024]H. Du, L. Ren, Y. Wang, X. Cao, C. Sun,Advancements in perception system with multi-sensor fusion for embodied agents,Information Fusion (2024) 102859.
13. Martinez-Carranza and Rascon [2020]J. Martinez-Carranza, C. Rascon,A review on auditory perception for unmanned aerial vehicles,Sensors 20 (2020) 7276.
14. Zhang et al. [2023]J. Zhang, S. Xu, Y. Zhao, J. Sun, S. Xu, X. Zhang,Aerial orthoimage generation for uav remote sensing,Information Fusion 89 (2023) 91–120.
15. Mittal et al. [2020]P. Mittal, R. Singh, A. Sharma,Deep learning-based object detection in low-altitude uav datasets: A survey,Image and Vision computing 104 (2020) 104046.
16. Liu et al. [2020]M. Liu, X. Wang, A. Zhou, X. Fu, Y. Ma, C. Piao,Uav-yolo: Small object detection on unmanned aerial vehicle perspective,Sensors 20 (2020) 2238.
17. Girisha et al. [2019]S. Girisha, M. P. MM, U. Verma, R. M. Pai,Semantic segmentation of uav aerial videos using convolutional neural networks,in: 2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE), IEEE, 2019, pp. 21–27.
18. Liu et al. [2021]S. Liu, J. Cheng, L. Liang, H. Bai, W. Dang,Light-weight semantic segmentation network for uav remote sensing images,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 14 (2021) 8287–8296.
19. Li et al. [2010]Z. Li, N. Hovakimyan, V. Dobrokhodov, I. Kaminer,Vision-based target tracking and motion estimation using a small uav,in: 49th IEEE Conference on Decision and Control (CDC), IEEE, 2010, pp. 2505–2510.
20. Dobrokhodov et al. [2006]V. N. Dobrokhodov, I. I. Kaminer, K. D. Jones, R. Ghabcheloo,Vision-based tracking and motion estimation for moving targets using small uavs,in: 2006 American Control Conference, IEEE, 2006, pp. 6–pp.
21. Mascaro et al. [2018]R. Mascaro, L. Teixeira, T. Hinzmann, R. Siegwart, M. Chli,Gomsf: Graph-optimization based multi-sensor fusion for robust uav pose estimation,in: 2018 IEEE international conference on robotics and automation (ICRA), IEEE, 2018, pp. 1421–1428.
22. Wan et al. [2022]L. Wan, R. Liu, L. Sun, H. Nie, X. Wang,Uav swarm based radar signal sorting via multi-source data fusion: A deep transfer learning framework,Information Fusion 78 (2022) 90–101.
23. Rezwan and Choi [2022]S. Rezwan, W. Choi,Artificial intelligence approaches for uav navigation: Recent advances and future challenges,IEEE access 10 (2022) 26320–26339.
24. Gyagenda et al. [2022]N. Gyagenda, J. V. Hatilima, H. Roth, V. Zhmud,A review of gnss-independent uav navigation techniques,Robotics and Autonomous Systems 152 (2022) 104069.
25. Balamurugan et al. [2016]G. Balamurugan, J. Valarmathi, V. Naidu,Survey on uav navigation in gps denied environments,in: 2016 International conference on signal processing, communication, power and embedded system (SCOPES), IEEE, 2016, pp. 198–204.
26. McEnroe et al. [2022]P. McEnroe, S. Wang, M. Liyanage,A survey on the convergence of edge computing and ai for uavs: Opportunities and challenges,IEEE Internet of Things Journal 9 (2022) 15435–15459.
27. Neumann and Bartholmai [2015]P. P. Neumann, M. Bartholmai,Real-time wind estimation on a micro unmanned aerial vehicle using its inertial measurement unit,Sensors and Actuators A: Physical 235 (2015) 300–310.
28. Barbieri et al. [2019]L. Barbieri, S. T. Kral, S. C. Bailey, A. E. Frazier, J. D. Jacob, J. Reuder, D. Brus, P. B. Chilson, C. Crick, C. Detweiler, et al.,Intercomparison of small unmanned aircraft system (suas) measurements for atmospheric science during the lapse-rate campaign,Sensors 19 (2019) 2179.
29. Couturier and Akhloufi [2021]A. Couturier, M. A. Akhloufi,A review on absolute visual localization for uav,Robotics and Autonomous Systems 135 (2021) 103666.
30. Rovira-Sugranes et al. [2022]A. Rovira-Sugranes, A. Razi, F. Afghah, J. Chakareski,A review of ai-enabled routing protocols for uav networks: Trends, challenges, and future outlook,Ad Hoc Networks 130 (2022) 102790.
31. Atif et al. [2021]M. Atif, R. Ahmad, W. Ahmad, L. Zhao, J. J. Rodrigues,Uav-assisted wireless localization for search and rescue,IEEE Systems Journal 15 (2021) 3261–3272.
32. Lu et al. [2018]Y. Lu, Z. Xue, G.-S. Xia, L. Zhang,A survey on vision-based uav navigation,Geo-spatial information science 21 (2018) 21–32.
33. Gupta and Fernando [2022]A. Gupta, X. Fernando,Simultaneous localization and mapping (slam) and data fusion in unmanned aerial vehicles: Recent advances and challenges,Drones 6 (2022) 85.
34. Kassas et al. [2024]Z. M. Kassas, N. Khairallah, J. J. Khalife, C. Lee, J. Jurado, S. Wachtel, J. Duede, Z. Hoeffner, T. Hulsey, R. Quirarte, et al.,Aircraft navigation in gnss-denied environments via radio slam with terrestrial signals of opportunity,IEEE Transactions on Intelligent Transportation Systems (2024).
35. Tisdale et al. [2009]J. Tisdale, Z. Kim, J. K. Hedrick,Autonomous uav path planning and estimation,IEEE Robotics & Automation Magazine 16 (2009) 35–42.
36. Goerzen et al. [2010]C. Goerzen, Z. Kong, B. Mettler,A survey of motion planning algorithms from the perspective of autonomous uav guidance,Journal of Intelligent and Robotic Systems 57 (2010) 65–100.
37. Hong et al. [2021]Y. Hong, S. Kim, Y. Kim, J. Cha,Quadrotor path planning using a\* search algorithm and minimum snap trajectory generation,ETRI Journal 43 (2021) 1013–1023.
38. Chai et al. [2022]X. Chai, Z. Zheng, J. Xiao, L. Yan, B. Qu, P. Wen, H. Wang, Y. Zhou, H. Sun,Multi-strategy fusion differential evolution algorithm for uav path planning in complex environment,Aerospace Science and Technology 121 (2022) 107287.
39. Xiao et al. [2021]S. Xiao, X. Tan, J. Wang,A simulated annealing algorithm and grid map-based uav coverage path planning method for 3d reconstruction,Electronics 10 (2021) 853.
40. Ait-Saadi et al. [2022]A. Ait-Saadi, Y. Meraihi, A. Soukane, A. Ramdane-Cherif, A. B. Gabis,A novel hybrid chaotic aquila optimization algorithm with simulated annealing for unmanned aerial vehicles path planning,Computers and Electrical Engineering 104 (2022) 108461.
41. Phung and Ha [2021]M. D. Phung, Q. P. Ha,Safety-enhanced uav path planning with spherical vector-based particle swarm optimization,Applied Soft Computing 107 (2021) 107376.
42. Yu et al. [2022]Z. Yu, Z. Si, X. Li, D. Wang, H. Song,A novel hybrid particle swarm optimization algorithm for path planning of uavs,IEEE Internet of Things Journal 9 (2022) 22547–22558.
43. He et al. [2021]W. He, X. Qi, L. Liu,A novel hybrid particle swarm optimization for multi-uav cooperate path planning,Applied Intelligence 51 (2021) 7350–7364.
44. Yang et al. [2023]Y. Yang, X. Xiong, Y. Yan,Uav formation trajectory planning algorithms: A review,Drones 7 (2023) 62.
45. Liu et al. [2021]H. Liu, J. Ge, Y. Wang, J. Li, K. Ding, Z. Zhang, Z. Guo, W. Li, J. Lan,Multi-uav optimal mission assignment and path planning for disaster rescue using adaptive genetic algorithm and improved artificial bee colony method,in: Actuators, volume 11, MDPI, 2021, p. 4.
46. Han et al. [2022]Z. Han, M. Chen, S. Shao, Q. Wu,Improved artificial bee colony algorithm-based path planning of unmanned autonomous helicopter using multi-strategy evolutionary learning,Aerospace Science and Technology 122 (2022) 107374.
47. Pan et al. [2021]Y. Pan, Y. Yang, W. Li,A deep learning trained by genetic algorithm to improve the efficiency of path planning for data collection with multi-uav,Ieee Access 9 (2021) 7994–8005.
48. Cui and Wang [2021]Z. Cui, Y. Wang,Uav path planning based on multi-layer reinforcement learning technique,Ieee Access 9 (2021) 59486–59497.
49. Heidari et al. [2023]A. Heidari, N. Jafari Navimipour, M. Unal, G. Zhang,Machine learning applications in internet-of-drones: Systematic review, recent deployments, and open issues,ACM Computing Surveys 55 (2023) 1–45.
50. He et al. [2021]L. He, N. Aouf, B. Song,Explainable deep reinforcement learning for uav autonomous path planning,Aerospace science and technology 118 (2021) 107052.
51. Zhu et al. [2021]B. Zhu, E. Bedeer, H. H. Nguyen, R. Barton, J. Henry,Uav trajectory planning in wireless sensor networks for energy consumption minimization by deep reinforcement learning,IEEE Transactions on Vehicular Technology 70 (2021) 9540–9554.
52. Guo et al. [2023]Y. Guo, X. Liu, Q. Jia, X. Liu, W. Zhang,Hpo-rrt\*: A sampling-based algorithm for uav real-time path planning in a dynamic environment,Complex & Intelligent Systems 9 (2023) 7133–7153.
53. Lin and Saripalli [2017]Y. Lin, S. Saripalli,Sampling-based path planning for uav collision avoidance,IEEE Transactions on Intelligent Transportation Systems 18 (2017) 3179–3192.
54. Puente-Castro et al. [2021]A. Puente-Castro, D. Rivero, A. Pazos, E. Fernandez-Blanco,Using reinforcement learning in the path planning of swarms of uavs for the photographic capture of terrains,Engineering Proceedings 7 (2021) 32.
55. Puente-Castro et al. [2022]A. Puente-Castro, D. Rivero, A. Pazos, E. Fernandez-Blanco,A review of artificial intelligence applied to path planning in uav swarms,Neural Computing and Applications 34 (2022) 153–170.
56. Pan et al. [2021]Z. Pan, C. Zhang, Y. Xia, H. Xiong, X. Shao,An improved artificial potential field method for path planning and formation control of the multi-uav systems,IEEE Transactions on Circuits and Systems II: Express Briefs 69 (2021) 1129–1133.
57. Zhao et al. [2021]C. Zhao, J. Liu, M. Sheng, W. Teng, Y. Zheng, J. Li,Multi-uav trajectory planning for energy-efficient content coverage: A decentralized learning-based approach,IEEE Journal on Selected Areas in Communications 39 (2021) 3193–3207.
58. Li et al. [2024]K. Li, X. Yan, Y. Han,Multi-mechanism swarm optimization for multi-uav task assignment and path planning in transmission line inspection under multi-wind field,Applied Soft Computing 150 (2024) 111033.
59. Fahlstrom et al. [2022]P. G. Fahlstrom, T. J. Gleason, M. H. Sadraey, Introduction to UAV systems, John Wiley & Sons, 2022.
60. Harvey et al. [2022]C. Harvey, L. L. Gamble, C. R. Bolander, D. F. Hunsaker, J. J. Joo, D. J. Inman,A review of avian-inspired morphing for uav flight control,Progress in Aerospace Sciences 132 (2022) 100825.
61. Mahmoodabadi and Rezaee Babak [2020]M. J. Mahmoodabadi, N. Rezaee Babak,Fuzzy adaptive robust proportional–integral–derivative control optimized by the multi-objective grasshopper optimization algorithm for a nonlinear quadrotor,Journal of Vibration and Control 26 (2020) 1574–1589.
62. Bello et al. [2022]A. B. Bello, F. Navarro, J. Raposo, M. Miranda, A. Zazo, M. Álvarez,Fixed-wing uav flight operation under harsh weather conditions: A case study in livingston island glaciers, antarctica,Drones 6 (2022) 384.
63. Koksal et al. [2020]N. Koksal, H. An, B. Fidan,Backstepping-based adaptive control of a quadrotor uav with guaranteed tracking performance,ISA transactions 105 (2020) 98–110.
64. Zuo et al. [2022]Z. Zuo, C. Liu, Q.-L. Han, J. Song,Unmanned aerial vehicles: Control methods and future challenges,IEEE/CAA Journal of Automatica Sinica 9 (2022) 601–614.
65. Fei et al. [2021]J. Fei, Y. Chen, L. Liu, Y. Fang,Fuzzy multiple hidden layer recurrent neural control of nonlinear system using terminal sliding-mode controller,IEEE transactions on cybernetics 52 (2021) 9519–9534.
66. Gambhire et al. [2021]S. Gambhire, D. R. Kishore, P. Londhe, S. Pawar,Review of sliding mode based control techniques for control system applications,International Journal of dynamics and control 9 (2021) 363–378.
67. Jasim and Veres [2020]O. A. Jasim, S. M. Veres,A robust controller for multi rotor uavs,Aerospace Science and Technology 105 (2020) 106010.
68. Basiri et al. [2022]A. Basiri, V. Mariani, G. Silano, M. Aatif, L. Iannelli, L. Glielmo,A survey on the application of path-planning algorithms for multi-rotor uavs in precision agriculture,The Journal of Navigation 75 (2022) 364–383.
69. Boroujeni et al. [2024]S. P. H. Boroujeni, A. Razi, S. Khoshdel, F. Afghah, J. L. Coen, L. O’Neill, P. Fule, A. Watts, N.-M. T. Kokolakis, K. G. Vamvoudakis,A comprehensive survey of research towards ai-enabled unmanned aerial systems in pre-, active-, and post-wildfire management,Information Fusion (2024) 102369.
70. Campion et al. [2018]M. Campion, P. Ranganathan, S. Faruque,Uav swarm communication and control architectures: a review,Journal of Unmanned Vehicle Systems 7 (2018) 93–106.
71. Sharma et al. [2020]A. Sharma, P. Vanjani, N. Paliwal, C. M. W. Basnayaka, D. N. K. Jayakody, H.-C. Wang, P. Muthuchidambaranathan,Communication and networking technologies for uavs: A survey,Journal of Network and Computer Applications 168 (2020) 102739.
72. Hentati and Fourati [2020]A. I. Hentati, L. C. Fourati,Comprehensive survey of uavs communication networks,Computer Standards & Interfaces 72 (2020) 103451.
73. Wu et al. [2021]Q. Wu, J. Xu, Y. Zeng, D. W. K. Ng, N. Al-Dhahir, R. Schober, A. L. Swindlehurst,A comprehensive overview on 5g-and-beyond networks with uavs: From communications to sensing and intelligence,IEEE Journal on Selected Areas in Communications 39 (2021) 2912–2945.
74. Ullah et al. [2020]Z. Ullah, F. Al-Turjman, L. Mostarda,Cognition in uav-aided 5g and beyond communications: A survey,IEEE Transactions on Cognitive Communications and Networking 6 (2020) 872–891.
75. Alladi et al. [2020]T. Alladi, V. Chamola, N. Sahu, M. Guizani,Applications of blockchain in unmanned aerial vehicles: A review,Vehicular Communications 23 (2020) 100249.
76. Kumar et al. [2021]R. Kumar, P. Kumar, R. Tripathi, G. P. Gupta, T. R. Gadekallu, G. Srivastava,Sp2f: A secured privacy-preserving framework for smart agricultural unmanned aerial vehicles,Computer Networks 187 (2021) 107819.
77. Messaoudi et al. [2023]K. Messaoudi, O. S. Oubbati, A. Rachedi, A. Lakas, T. Bendouma, N. Chaib,A survey of uav-based data collection: Challenges, solutions and future perspectives,Journal of network and computer applications 216 (2023) 103670.
78. Yoo et al. [2022]M. Yoo, Y. Na, H. Song, G. Kim, J. Yun, S. Kim, C. Moon, K. Jo,Motion estimation and hand gesture recognition-based human–uav interaction approach in real time,Sensors 22 (2022) 2513.
79. Li et al. [2021]T. Li, J. Liu, W. Zhang, Y. Ni, W. Wang, Z. Li,Uav-human: A large benchmark for human behavior understanding with unmanned aerial vehicles,in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2021, pp. 16266–16275.
80. Sun et al. [2022]Z. Sun, Q. Ke, H. Rahmani, M. Bennamoun, G. Wang, J. Liu,Human action recognition from various data modalities: A review,IEEE transactions on pattern analysis and machine intelligence 45 (2022) 3200–3225.
81. Zhang et al. [2020]J. Zhang, Z. Yu, X. Wang, Y. Lyu, S. Mao, S. C. Periaswamy, J. Patton, X. Wang,Rfhui: An rfid based human-unmanned aerial vehicle interaction system in an indoor environment,Digital Communications and Networks 6 (2020) 14–22.
82. Deng et al. [2023]T. Deng, Z. Huo, L. Zhang, Z. Dong, L. Niu, X. Kang, X. Huang,A vr-based bci interactive system for uav swarm control,Biomedical Signal Processing and Control 85 (2023) 104944.
83. Xiao et al. [2024]Z. Xiao, P. Li, C. Liu, H. Gao, X. Wang,Macns: A generic graph neural network integrated deep reinforcement learning based multi-agent collaborative navigation system for dynamic trajectory planning,Information Fusion 105 (2024) 102250.
84. Jiao et al. [2020]R. Jiao, Z. Wang, R. Chu, M. Dong, Y. Rong, W. Chou,An intuitive end-to-end human-uav interaction system for field exploration,Frontiers in Neurorobotics 13 (2020) 117.
85. Divband Soorati et al. [2021]M. Divband Soorati, J. Clark, J. Ghofrani, D. Tarapore, S. D. Ramchurn,Designing a user-centered interaction interface for human–swarm teaming,Drones 5 (2021) 131.
86. Zheng et al. [2020]Y.-J. Zheng, Y.-C. Du, Z.-L. Su, H.-F. Ling, M.-X. Zhang, S.-Y. Chen,Evolutionary human-uav cooperation for transmission network restoration,IEEE Transactions on Industrial Informatics 17 (2020) 1648–1657.
87. Lim et al. [2021]Y. Lim, N. Pongsakornsathien, A. Gardi, R. Sabatini, T. Kistan, N. Ezer, D. J. Bursch,Adaptive human-robot interactions for multiple unmanned aerial vehicles,Robotics 10 (2021) 12.
88. Chang et al. [2020]W. Chang, W. Lizhen, Y. Chao, W. Zhichao, L. Han, Y. Chao,Coactive design of explainable agent-based task planning and deep reinforcement learning for human-uavs teamwork,Chinese Journal of Aeronautics 33 (2020) 2930–2945.
89. Cauchard et al. [2021]J. R. Cauchard, M. Khamis, J. Garcia, M. Kljun, A. M. Brock,Toward a roadmap for human-drone interaction,Interactions 28 (2021) 76–81.
90. Ribeiro et al. [2021]R. Ribeiro, J. Ramos, D. Safadinho, A. Reis, C. Rabadão, J. Barroso, A. Pereira,Web ar solution for uav pilot training and usability testing,Sensors 21 (2021) 1456.
91. Mohiuddin et al. [2023]A. Mohiuddin, T. Taha, Y. Zweiri, D. Gan,Dual-uav payload transportation using optimized velocity profiles via real-time dynamic programming,Drones 7 (2023) 171.
92. González-Jorge et al. [2017]H. González-Jorge, J. Martínez-Sánchez, M. Bueno, P. Arias,Unmanned aerial systems for civil applications: A review,Drones 1 (2017) 2.
93. Hadi et al. [2014]G. S. Hadi, R. Varianto, B. R. Trilaksono, A. Budiyono,Autonomous uav system development for payload dropping mission,Journal of Instrumentation, Automation and Systems 1 (2014) 72–77.
94. Kusznir and Smoczek [2020]T. Kusznir, J. Smoczek,Sliding mode-based control of a uav quadrotor for suppressing the cable-suspended payload vibration,Journal of Control Science and Engineering 2020 (2020) 5058039.
95. Lee and Son [2020]S. Lee, H. Son,Antisway control of a multirotor with cable-suspended payload,IEEE Transactions on Control Systems Technology 29 (2020) 2630–2638.
96. Mohammadi et al. [2020]K. Mohammadi, S. Sirouspour, A. Grivani,Control of multiple quad-copters with a cable-suspended payload subject to disturbances,IEEE/ASME Transactions on Mechatronics 25 (2020) 1709–1718.
97. Lee et al. [2021]C. Lee, S. Kim, B. Chu,A survey: Flight mechanism and mechanical structure of the uav,International Journal of Precision Engineering and Manufacturing 22 (2021) 719–743.
98. Zhou et al. [2020]Y. Zhou, B. Rao, W. Wang,Uav swarm intelligence: Recent advances and future trends,Ieee Access 8 (2020) 183856–183878.
99. Chakraborty and Kar [2017]A. Chakraborty, A. K. Kar,Swarm intelligence: A review of algorithms,Nature-inspired computing and optimization: Theory and applications (2017) 475–494.
100. Lamport [2001]L. Lamport,Paxos made simple,ACM SIGACT News (Distributed Computing Column) 32, 4 (Whole Number 121, December 2001) (2001) 51–58.
101. Kennedy and Eberhart [1995]J. Kennedy, R. Eberhart,Particle swarm optimization,in: Proceedings of ICNN’95-international conference on neural networks, volume 4, ieee, 1995, pp. 1942–1948.
102. Jones and Matarić [2018]C. Jones, M. J. Matarić,Behavior-based coordination in multi-robot systems,in: Autonomous Mobile Robots, CRC Press, 2018, pp. 549–570.
103. Ma et al. [2022]L. Ma, B. Lin, W. Zhang, J. Tao, X. Zhu, H. Chen,A survey of research on the distributed cooperation method of the uav swarm based on swarm intelligence,in: 2022 IEEE 13th International Conference on Software Engineering and Service Science (ICSESS), IEEE, 2022, pp. 305–309.
104. Schwarzrock et al. [2018]J. Schwarzrock, I. Zacarias, A. L. Bazzan, R. Q. de Araujo Fernandes, L. H. Moreira, E. P. de Freitas,Solving task allocation problem in multi unmanned aerial vehicles systems using swarm intelligence,Engineering Applications of Artificial Intelligence 72 (2018) 10–20.
105. Zhang and Chen [2021]X. Zhang, X. Chen,Uav task allocation based on clone selection algorithm,Wireless Communications and Mobile Computing 2021 (2021) 5518927.
106. Kudo and Cai [2023]F. Kudo, K. Cai,A tsp-based online algorithm for multi-task multi-agent pickup and delivery,IEEE Robotics and Automation Letters (2023).
107. Sarkar et al. [2018]C. Sarkar, H. S. Paul, A. Pal,A scalable multi-robot task allocation algorithm,in: 2018 IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2018, pp. 5022–5027.
108. Darrah et al. [2005]M. Darrah, W. Niland, B. Stolarik,Multiple uav dynamic task allocation using mixed integer linear programming in a sead mission,in: Infotech@ Aerospace, 2005, p. 7164.
109. Ye et al. [2020]F. Ye, J. Chen, Y. Tian, T. Jiang,Cooperative multiple task assignment of heterogeneous uavs using a modified genetic algorithm with multi-type-gene chromosome encoding strategy,Journal of intelligent & robotic systems 100 (2020) 615–627.
110. Han et al. [2021]S. Han, C. Fan, X. Li, X. Luo, Z. Liu,A modified genetic algorithm for task assignment of heterogeneous unmanned aerial vehicle system,Measurement and Control 54 (2021) 994–1014.
111. Yan et al. [2024]F. Yan, J. Chu, J. Hu, X. Zhu,Cooperative task allocation with simultaneous arrival and resource constraint for multi-uav using a genetic algorithm,Expert Systems with Applications 245 (2024) 123023.
112. Jiang et al. [2017]X. Jiang, Q. Zhou, Y. Ye,Method of task assignment for uav based on particle swarm optimization in logistics,in: Proceedings of the 2017 international conference on intelligent systems, metaheuristics & swarm intelligence, 2017, pp. 113–117.
113. Gao et al. [2018]Y. Gao, Y. Zhang, S. Zhu, Y. Sun,Multi-uav task allocation based on improved algorithm of multi-objective particle swarm optimization,in: 2018 International conference on cyber-enabled distributed computing and knowledge discovery (CyberC), IEEE, 2018, pp. 443–4437.
114. Choi et al. [2010]H.-J. Choi, J.-B. Seo, Y.-D. Kim,Task assignment of multiple uavs using milp and ga,Journal of the Korean Society for Aeronautical & Space Sciences 38 (2010) 427–436.
115. Yang et al. [2019]J. Yang, X. You, G. Wu, M. M. Hassan, A. Almogren, J. Guna,Application of reinforcement learning in uav cluster task scheduling,Future generation computer systems 95 (2019) 140–148.
116. Yin et al. [2022]Y. Yin, Y. Guo, Q. Su, Z. Wang,Task allocation of multiple unmanned aerial vehicles based on deep transfer reinforcement learning,Drones 6 (2022) 215.
117. Peng et al. [2021]Q. Peng, H. Wu, R. Xue,Review of dynamic task allocation methods for uav swarms oriented to ground targets,Complex System Modeling and Simulation 1 (2021) 163–175.
118. Skaltsis et al. [2023]G. M. Skaltsis, H.-S. Shin, A. Tsourdos,A review of task allocation methods for uavs,Journal of Intelligent & Robotic Systems 109 (2023) 76.
119. Cheng et al. [2016]Q. Cheng, D. Yin, J. Yang, L. Shen,An auction-based multiple constraints task allocation algorithm for multi-uav system,in: 2016 International Conference on Cybernetics, Robotics and Control (CRC), IEEE, 2016, pp. 1–5.
120. Duan et al. [2019]X. Duan, H. Liu, H. Tang, Q. Cai, F. Zhang, X. Han,A novel hybrid auction algorithm for multi-uavs dynamic task assignment,IEEE access 8 (2019) 86207–86222.
121. Zhang et al. [2022]Z. Zhang, H. Liu, G. Wu,A dynamic task scheduling method for multiple uavs based on contract net protocol,Sensors 22 (2022) 4486.
122. Wang et al. [2023]G. Wang, X. Lv, X. Yan,A two-stage distributed task assignment algorithm based on contract net protocol for multi-uav cooperative reconnaissance task reassignment in dynamic environments,Sensors 23 (2023) 7980.
123. Campion et al. [2018]M. Campion, P. Ranganathan, S. Faruque,A review and future directions of uav swarm communication architectures,in: 2018 IEEE international conference on electro/information technology (EIT), IEEE, 2018, pp. 0903–0908.
124. Bekmezci et al. [2013]I. Bekmezci, O. K. Sahingoz, Ş. Temel,Flying ad-hoc networks (fanets): A survey,Ad Hoc Networks 11 (2013) 1254–1270.
125. Javed et al. [2024]S. Javed, A. Hassan, R. Ahmad, W. Ahmed, R. Ahmed, A. Saadat, M. Guizani,State-of-the-art and future research challenges in uav swarms,IEEE Internet of Things Journal (2024).
126. Turker et al. [2016]T. Turker, G. Yilmaz, O. K. Sahingoz,Gpu-accelerated flight route planning for multi-uav systems using simulated annealing,in: Artificial Intelligence: Methodology, Systems, and Applications: 17th International Conference, AIMSA 2016, Varna, Bulgaria, September 7-10, 2016, Proceedings 17, Springer, 2016, pp. 279–288.
127. Wei and Wei [2009]L. Wei, Z. Wei,Path planning of uavs swarm using ant colony system,in: 2009 Fifth International Conference on Natural Computation, volume 5, IEEE, 2009, pp. 288–292.
128. Ragi and Mittelmann [2017]S. Ragi, H. D. Mittelmann,Mixed-integer nonlinear programming formulation of a uav path optimization problem,in: 2017 American Control Conference (ACC), IEEE, 2017, pp. 406–411.
129. Kool et al. [2018]W. Kool, H. Van Hoof, M. Welling,Attention, learn to solve routing problems!,arXiv preprint arXiv:1803.08475 (2018).
130. Xia and Yudi [2018]C. Xia, A. Yudi,Multi—uav path planning based on improved neural network,in: 2018 Chinese Control And Decision Conference (CCDC), IEEE, 2018, pp. 354–359.
131. Sanna et al. [2021]G. Sanna, S. Godio, G. Guglieri,Neural network based algorithm for multi-uav coverage path planning,in: 2021 International Conference on Unmanned Aircraft Systems (ICUAS), IEEE, 2021, pp. 1210–1217.
132. Ouyang et al. [2023]Q. Ouyang, Z. Wu, Y. Cong, Z. Wang,Formation control of unmanned aerial vehicle swarms: A comprehensive review,Asian Journal of Control 25 (2023) 570–593.
133. Bu et al. [2024]Y. Bu, Y. Yan, Y. Yang,Advancement challenges in uav swarm formation control: A comprehensive review,Drones 8 (2024) 320.
134. Askari et al. [2015]A. Askari, M. Mortazavi, H. Talebi,Uav formation control via the virtual structure approach,Journal of Aerospace Engineering 28 (2015) 04014047.
135. Lewis and Tan [1997]M. A. Lewis, K.-H. Tan,High precision formation control of mobile robots using virtual structures,Autonomous robots 4 (1997) 387–403.
136. Desai et al. [1998]J. P. Desai, J. Ostrowski, V. Kumar,Controlling formations of multiple mobile robots,in: Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No. 98CH36146), volume 4, IEEE, 1998, pp. 2864–2869.
137. Huang et al. [2022]H. Huang, A. V. Savkin, W. Ni,Decentralized navigation of a uav team for collaborative covert eavesdropping on a group of mobile ground nodes,IEEE Transactions on Automation Science and Engineering 19 (2022) 3932–3941.
138. Sun et al. [2022]S. Sun, Y. Liu, S. Guo, G. Li, X. Yuan,Observation-driven multiple uav coordinated standoff target tracking based on model predictive control,Tsinghua Science and Technology 27 (2022) 948–963.
139. Duan et al. [2021]H. Duan, L. Xin, Y. Shi,Homing pigeon-inspired autonomous navigation system for unmanned aerial vehicles,IEEE Transactions On Aerospace and Electronic Systems 57 (2021) 2218–2224.
140. Tao et al. [2023]C. Tao, R. Zhang, Z. Song, B. Wang, Y. Jin,Multi-uav formation control in complex conditions based on improved consistency algorithm,Drones 7 (2023) 185.
141. Brown [2020]T. B. Brown,Language models are few-shot learners,arXiv preprint arXiv:2005.14165 (2020).
142. Ouyang et al. [2022]L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al.,Training language models to follow instructions with human feedback,Advances in neural information processing systems 35 (2022) 27730–27744.
143. Achiam et al. [2023]J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat, et al.,Gpt-4 technical report,arXiv preprint arXiv:2303.08774 (2023).
144. Anthropic [2023]Anthropic, Model card and evaluations for claude models, 2023. URL: [https://www-cdn.anthropic.com/files/4zrzovbb/website/bd2a28d2535bfb0494cc8e2a3bf135d2e7523226.pdf](https://www-cdn.anthropic.com/files/4zrzovbb/website/bd2a28d2535bfb0494cc8e2a3bf135d2e7523226.pdf).
145. Anthropic [2022]Anthropic,Constitutional ai: Harmlessness from ai feedback (2022). URL: [https://en.wikipedia.org/wiki/Claude_%28language_model%29](https://en.wikipedia.org/wiki/Claude_%28language_model%29).
146. Anthropic [2023]Anthropic, Mapping the mind of a large language model, 2023. URL: [https://www.anthropic.com/research/mapping-mind-language-model](https://www.anthropic.com/research/mapping-mind-language-model).
147. Jiang et al. [2023]A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. d. l. Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier, et al.,Mistral 7b,arXiv preprint arXiv:2310.06825 (2023).
148. Jiang et al. [2024]A. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary, C. Bamford, D. S. Chaplot, D. d. l. Casas, E. B. Hanna, F. Bressand, et al.,Mixtral of experts,arXiv preprint arXiv:2401.04088 (2024).
149. Chowdhery et al. [2023]A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al.,Palm: Scaling language modeling with pathways,Journal of Machine Learning Research 24 (2023) 1–113.
150. Driess et al. [2023]D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter, A. Wahid, J. Tompson, Q. Vuong, T. Yu, et al.,Palm-e: An embodied multimodal language model,arXiv preprint arXiv:2303.03378 (2023).
151. Team et al. [2023]G. Team, R. Anil, S. Borgeaud, J.-B. Alayrac, J. Yu, R. Soricut, J. Schalkwyk, A. M. Dai, A. Hauth, K. Millican, et al.,Gemini: a family of highly capable multimodal models,arXiv preprint arXiv:2312.11805 (2023).
152. Reid et al. [2024]M. Reid, N. Savinov, D. Teplyashin, D. Lepikhin, T. Lillicrap, J.-b. Alayrac, R. Soricut, A. Lazaridou, O. Firat, J. Schrittwieser, et al.,Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,arXiv preprint arXiv:2403.05530 (2024).
153. Touvron et al. [2023a]H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, et al.,Llama: Open and efficient foundation language models,arXiv preprint arXiv:2302.13971 (2023a).
154. Touvron et al. [2023b]H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al.,Llama 2: Open foundation and fine-tuned chat models,arXiv preprint arXiv:2307.09288 (2023b).
155. Dubey et al. [2024]A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur, A. Schelten, A. Yang, A. Fan, et al.,The llama 3 herd of models,arXiv preprint arXiv:2407.21783 (2024).
156. Chiang et al. [2023]W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E. Gonzalez, et al.,Vicuna: An open-source chatbot impressing gpt-4 with 90%\* chatgpt quality,See https://vicuna. lmsys. org (accessed 14 April 2023) 2 (2023) 6.
157. Bai et al. [2023]J. Bai, S. Bai, Y. Chu, Z. Cui, K. Dang, X. Deng, Y. Fan, W. Ge, Y. Han, F. Huang, et al.,Qwen technical report,arXiv preprint arXiv:2309.16609 (2023).
158. Yang et al. [2024]A. Yang, B. Yang, B. Hui, B. Zheng, B. Yu, C. Zhou, C. Li, C. Li, D. Liu, F. Huang, et al.,Qwen2 technical report,arXiv preprint arXiv:2407.10671 (2024).
159. Cai et al. [2024]Z. Cai, M. Cao, H. Chen, K. Chen, K. Chen, X. Chen, X. Chen, Z. Chen, Z. Chen, P. Chu, et al.,Internlm2 technical report,arXiv preprint arXiv:2403.17297 (2024).
160. Zhao et al. [2023]Y. Zhao, Z. Lin, D. Zhou, Z. Huang, J. Feng, B. Kang,Bubogpt: Enabling visual grounding in multi-modal llms,arXiv preprint arXiv:2307.08581 (2023).
161. Du et al. [2021]Z. Du, Y. Qian, X. Liu, M. Ding, J. Qiu, Z. Yang, J. Tang,Glm: General language model pretraining with autoregressive blank infilling,arXiv preprint arXiv:2103.10360 (2021).
162. Zeng et al. [2022]A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, M. Ding, Z. Yang, Y. Xu, W. Zheng, X. Xia, et al.,Glm-130b: An open bilingual pre-trained model,arXiv preprint arXiv:2210.02414 (2022).
163. GLM et al. [2024]T. GLM, A. Zeng, B. Xu, B. Wang, C. Zhang, D. Yin, D. Zhang, D. Rojas, G. Feng, H. Zhao, et al.,Chatglm: A family of large language models from glm-130b to glm-4 all tools,arXiv preprint arXiv:2406.12793 (2024).
164. Bi et al. [2024]X. Bi, D. Chen, G. Chen, S. Chen, D. Dai, C. Deng, H. Ding, K. Dong, Q. Du, Z. Fu, et al.,Deepseek llm: Scaling open-source language models with longtermism,arXiv preprint arXiv:2401.02954 (2024).
165. Liu et al. [2024]A. Liu, B. Feng, B. Wang, B. Wang, B. Liu, C. Zhao, C. Dengr, C. Ruan, D. Dai, D. Guo, et al.,Deepseek-v2: A strong, economical, and efficient mixture-of-experts language model,arXiv preprint arXiv:2405.04434 (2024).
166. Guo et al. [2024]D. Guo, Q. Zhu, D. Yang, Z. Xie, K. Dong, W. Zhang, G. Chen, X. Bi, Y. Wu, Y. Li, et al.,Deepseek-coder: When the large language model meets programming–the rise of code intelligence,arXiv preprint arXiv:2401.14196 (2024).
167. OpenAI [2024]OpenAI, GPT-4V System Card, 2024. URL: [https://openai.com/index/gpt-4v-system-card/](https://openai.com/index/gpt-4v-system-card/), accessed: 2024-11-16.
168. Anthropic [2024]Anthropic, The claude 3 model family: Opus, sonnet, haiku, 2024. URL: [https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf), accessed on November 16, 2024.
169. Liu et al. [2024a]H. Liu, C. Li, Q. Wu, Y. J. Lee,Visual instruction tuning,Advances in neural information processing systems 36 (2024a).
170. Liu et al. [2024b]H. Liu, C. Li, Y. Li, Y. J. Lee,Improved baselines with visual instruction tuning,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024b, pp. 26296–26306.
171. Liu et al. [2024c]H. Liu, C. Li, Y. Li, B. Li, Y. Zhang, S. Shen, Y. J. Lee, Llava-next: Improved reasoning, ocr, and world knowledge, 2024c. URL: [https://llava-vl.github.io/blog/2024-01-30-llava-next/](https://llava-vl.github.io/blog/2024-01-30-llava-next/), accessed: 2024-11-16.
172. Lin et al. [2024]B. Lin, Z. Tang, Y. Ye, J. Cui, B. Zhu, P. Jin, J. Zhang, M. Ning, L. Yuan,Moe-llava: Mixture of experts for large vision-language models,arXiv preprint arXiv:2401.15947 (2024).
173. Xu et al. [2024]G. Xu, P. Jin, L. Hao, Y. Song, L. Sun, L. Yuan,Llava-o1: Let vision language models reason step-by-step,arXiv preprint arXiv:2411.10440 (2024).
174. Alayrac et al. [2022]J.-B. Alayrac, J. Donahue, P. Luc, A. Miech, I. Barr, Y. Hasson, K. Lenc, A. Mensch, K. Millican, M. Reynolds, et al.,Flamingo: a visual language model for few-shot learning,Advances in neural information processing systems 35 (2022) 23716–23736.
175. Li et al. [2022]J. Li, D. Li, C. Xiong, S. Hoi,Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation,in: International conference on machine learning, PMLR, 2022, pp. 12888–12900.
176. Li et al. [2023]J. Li, D. Li, S. Savarese, S. Hoi,Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models,in: International conference on machine learning, PMLR, 2023, pp. 19730–19742.
177. Dai et al. [2023]W. Dai, J. Li, D. Li, A. M. H. Tiong, J. Zhao, W. Wang, B. Li, P. Fung, S. Hoi, Instructblip: Towards general-purpose vision-language models with instruction tuning, 2023. URL: [https://arxiv.org/abs/2305.06500](https://arxiv.org/abs/2305.06500). [arXiv:2305.06500](http://arxiv.org/abs/2305.06500).
178. Li et al. [2025]Y. Li, C. Wang, J. Jia,Llama-vid: An image is worth 2 tokens in large language models,in: European Conference on Computer Vision, Springer, 2025, pp. 323–340.
179. Kim et al. [2024]W. Kim, C. Choi, W. Lee, W. Rhee,An image grid can be worth a video: Zero-shot video question answering using a vlm,arXiv preprint arXiv:2403.18406 (2024).
180. Maaz et al. [2023]M. Maaz, H. Rasheed, S. Khan, F. S. Khan,Video-chatgpt: Towards detailed video understanding via large vision and language models,arXiv preprint arXiv:2306.05424 (2023).
181. Wang et al. [2024]Z. Wang, S. Yu, E. Stengel-Eskin, J. Yoon, F. Cheng, G. Bertasius, M. Bansal,Videotree: Adaptive tree-based video representation for llm reasoning on long videos,arXiv preprint arXiv:2405.19209 (2024).
182. Zeng et al. [2021]Y. Zeng, X. Zhang, H. Li,Multi-grained vision language pre-training: Aligning texts with visual concepts,arXiv preprint arXiv:2111.08276 (2021).
183. Lu et al. [2024]P. Lu, B. Peng, H. Cheng, M. Galley, K.-W. Chang, Y. N. Wu, S.-C. Zhu, J. Gao,Chameleon: Plug-and-play compositional reasoning with large language models,Advances in Neural Information Processing Systems 36 (2024).
184. Ke et al. [2024]F. Ke, Z. Cai, S. Jahangard, W. Wang, P. D. Haghighi, H. Rezatofighi,Hydra: A hyper agent for dynamic compositional visual reasoning,arXiv preprint arXiv:2403.12884 (2024).
185. Gupta and Kembhavi [2023]T. Gupta, A. Kembhavi,Visual programming: Compositional visual reasoning without training,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp. 14953–14962.
186. Radford et al. [2021]A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, et al.,Learning transferable visual models from natural language supervision,in: International conference on machine learning, PMLR, 2021, pp. 8748–8763.
187. Yao et al. [2021]L. Yao, R. Huang, L. Hou, G. Lu, M. Niu, H. Xu, X. Liang, Z. Li, X. Jiang, C. Xu,Filip: Fine-grained interactive language-image pre-training,arXiv preprint arXiv:2111.07783 (2021).
188. Zhong et al. [2022]Y. Zhong, J. Yang, P. Zhang, C. Li, N. Codella, L. H. Li, L. Zhou, X. Dai, L. Yuan, Y. Li, et al.,Regionclip: Region-based language-image pretraining,in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2022, pp. 16793–16803.
189. Sun et al. [2023]Q. Sun, Y. Fang, L. Wu, X. Wang, Y. Cao,Eva-clip: Improved training techniques for clip at scale,arXiv preprint arXiv:2303.15389 (2023).
190. Li et al. [2022]L. H. Li, P. Zhang, H. Zhang, J. Yang, C. Li, Y. Zhong, L. Wang, L. Yuan, L. Zhang, J.-N. Hwang, et al.,Grounded language-image pre-training,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 10965–10975.
191. Zhang et al. [2022]H. Zhang, F. Li, S. Liu, L. Zhang, H. Su, J. Zhu, L. M. Ni, H.-Y. Shum,Dino: Detr with improved denoising anchor boxes for end-to-end object detection,arXiv preprint arXiv:2203.03605 (2022).
192. Liu et al. [2023]S. Liu, Z. Zeng, T. Ren, F. Li, H. Zhang, J. Yang, Q. Jiang, C. Li, J. Yang, H. Su, et al.,Grounding dino: Marrying dino with grounded pre-training for open-set object detection,arXiv preprint arXiv:2303.05499 (2023).
193. Oquab et al. [2023]M. Oquab, T. Darcet, T. Moutakanni, H. Vo, M. Szafraniec, V. Khalidov, P. Fernandez, D. Haziza, F. Massa, A. El-Nouby, et al.,Dinov2: Learning robust visual features without supervision,arXiv preprint arXiv:2304.07193 (2023).
194. Ranzinger et al. [2024]M. Ranzinger, G. Heinrich, J. Kautz, P. Molchanov,Am-radio: Agglomerative vision foundation model reduce all domains into one,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 12490–12500.
195. Zhou et al. [2024]G. Zhou, H. Pan, Y. LeCun, L. Pinto,Dino-wm: World models on pre-trained visual features enable zero-shot planning,arXiv preprint arXiv:2411.04983 (2024).
196. Cheng et al. [2024]T. Cheng, L. Song, Y. Ge, W. Liu, X. Wang, Y. Shan,Yolo-world: Real-time open-vocabulary object detection,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 16901–16911.
197. Lüddecke and Ecker [2022]T. Lüddecke, A. Ecker,Image segmentation using text and image prompts,in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2022, pp. 7086–7096.
198. Kirillov et al. [2023]A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao, S. Whitehead, A. C. Berg, W.-Y. Lo, et al.,Segment anything,in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023, pp. 4015–4026.
199. Xu et al. [2024]X. Xu, H. Chen, L. Zhao, Z. Wang, J. Zhou, J. Lu,Embodiedsam: Online segment any 3d thing in real time,arXiv preprint arXiv:2408.11811 (2024).
200. Zhou et al. [2024]Y. Zhou, J. Gu, T. Y. Chiang, F. Xiang, H. Su,Point-sam: Promptable 3d segmentation model for point clouds,arXiv preprint arXiv:2406.17741 (2024).
201. Yuan et al. [2025]H. Yuan, X. Li, C. Zhou, Y. Li, K. Chen, C. C. Loy,Open-vocabulary sam: Segment and recognize twenty-thousand classes interactively,in: European Conference on Computer Vision, Springer, 2025, pp. 419–437.
202. Pan et al. [2025]T. Pan, L. Tang, X. Wang, S. Shan,Tokenize anything via prompting,in: European Conference on Computer Vision, Springer, 2025, pp. 330–348.
203. Xiong et al. [2024]Y. Xiong, B. Varadarajan, L. Wu, X. Xiang, F. Xiao, C. Zhu, X. Dai, D. Wang, F. Sun, F. Iandola, et al.,Efficientsam: Leveraged masked image pretraining for efficient segment anything,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 16111–16121.
204. Zhang et al. [2023]C. Zhang, D. Han, Y. Qiao, J. U. Kim, S.-H. Bae, S. Lee, C. S. Hong,Faster segment anything: Towards lightweight sam for mobile applications,arXiv preprint arXiv:2306.14289 (2023).
205. Ravi et al. [2024]N. Ravi, V. Gabeur, Y.-T. Hu, R. Hu, C. Ryali, T. Ma, H. Khedr, R. Rädle, C. Rolland, L. Gustafson, et al.,Sam 2: Segment anything in images and videos,arXiv preprint arXiv:2408.00714 (2024).
206. Yang et al. [2024]C.-Y. Yang, H.-W. Huang, W. Chai, Z. Jiang, J.-N. Hwang,Samurai: Adapting segment anything model for zero-shot visual tracking with motion-aware memory,arXiv preprint arXiv:2411.11922 (2024).
207. Wang et al. [2023]X. Wang, X. Zhang, Y. Cao, W. Wang, C. Shen, T. Huang,Seggpt: Segmenting everything in context,arXiv preprint arXiv:2304.03284 (2023).
208. Yuan et al. [2024]Y. Yuan, W. Li, J. Liu, D. Tang, X. Luo, C. Qin, L. Zhang, J. Zhu,Osprey: Pixel understanding with visual instruction tuning,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 28202–28211.
209. Zou et al. [2024]X. Zou, J. Yang, H. Zhang, F. Li, L. Li, J. Wang, L. Wang, J. Gao, Y. J. Lee,Segment everything everywhere all at once,Advances in Neural Information Processing Systems 36 (2024).
210. Liu et al. [2024]Y. Liu, L. Kong, J. Cen, R. Chen, W. Zhang, L. Pan, K. Chen, Z. Liu,Segment any point cloud sequences by distilling vision foundation models,Advances in Neural Information Processing Systems 36 (2024).
211. Lai et al. [2024]X. Lai, Z. Tian, Y. Chen, Y. Li, Y. Yuan, S. Liu, J. Jia,Lisa: Reasoning segmentation via large language model,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 9579–9589.
212. Bhat et al. [2023]S. F. Bhat, R. Birkl, D. Wofk, P. Wonka, M. Müller,Zoedepth: Zero-shot transfer by combining relative and metric depth,arXiv preprint arXiv:2302.12288 (2023).
213. Zhu et al. [2024]R. Zhu, C. Wang, Z. Song, L. Liu, T. Zhang, Y. Zhang,Scaledepth: Decomposing metric depth estimation into scale prediction and relative depth estimation,arXiv preprint arXiv:2407.08187 (2024).
214. Yang et al. [2024a]L. Yang, B. Kang, Z. Huang, X. Xu, J. Feng, H. Zhao,Depth anything: Unleashing the power of large-scale unlabeled data,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024a, pp. 10371–10381.
215. Yang et al. [2024b]L. Yang, B. Kang, Z. Huang, Z. Zhao, X. Xu, J. Feng, H. Zhao,Depth anything v2,arXiv preprint arXiv:2406.09414 (2024b).
216. Bochkovskii et al. [2024]A. Bochkovskii, A. Delaunoy, H. Germain, M. Santos, Y. Zhou, S. R. Richter, V. Koltun,Depth pro: Sharp monocular metric depth in less than a second,arXiv preprint arXiv:2410.02073 (2024).
217. Vaswani [2017]A. Vaswani,Attention is all you need,Advances in Neural Information Processing Systems (2017).
218. Minaee et al. [2024]S. Minaee, T. Mikolov, N. Nikzad, M. Chenaghlu, R. Socher, X. Amatriain, J. Gao,Large language models: A survey,arXiv preprint arXiv:2402.06196 (2024).
219. Zhao et al. [2023]W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang, J. Zhang, Z. Dong, et al.,A survey of large language models,arXiv preprint arXiv:2303.18223 (2023).
220. Chang et al. [2024]Y. Chang, X. Wang, J. Wang, Y. Wu, L. Yang, K. Zhu, H. Chen, X. Yi, C. Wang, Y. Wang, et al.,A survey on evaluation of large language models,ACM Transactions on Intelligent Systems and Technology 15 (2024) 1–45.
221. Naveed et al. [2023]H. Naveed, A. U. Khan, S. Qiu, M. Saqib, S. Anwar, M. Usman, N. Akhtar, N. Barnes, A. Mian,A comprehensive overview of large language models,arXiv preprint arXiv:2307.06435 (2023).
222. Li et al. [2023]Y. Li, B. Hui, X. Xia, J. Yang, M. Yang, L. Zhang, S. Si, J. Liu, T. Liu, F. Huang, et al.,One shot learning as instruction data prospector for large language models,arXiv preprint arXiv:2312.10302 (2023).
223. Radford et al. [2019]A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al.,Language models are unsupervised multitask learners,OpenAI blog 1 (2019) 9.
224. Liu et al. [2021]J. Liu, D. Shen, Y. Zhang, B. Dolan, L. Carin, W. Chen,What makes good in-context examples for gpt-33?,arXiv preprint arXiv:2101.06804 (2021).
225. Dong et al. [2022]Q. Dong, L. Li, D. Dai, C. Zheng, J. Ma, R. Li, H. Xia, J. Xu, Z. Wu, T. Liu, et al.,A survey on in-context learning,arXiv preprint arXiv:2301.00234 (2022).
226. Kojima et al. [2022]T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, Y. Iwasawa,Large language models are zero-shot reasoners,Advances in neural information processing systems 35 (2022) 22199–22213.
227. Zhang et al. [2022]Z. Zhang, A. Zhang, M. Li, A. Smola,Automatic chain of thought prompting in large language models,arXiv preprint arXiv:2210.03493 (2022).
228. Wei et al. [2022]J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al.,Chain-of-thought prompting elicits reasoning in large language models,Advances in neural information processing systems 35 (2022) 24824–24837.
229. Feng et al. [2024]G. Feng, B. Zhang, Y. Gu, H. Ye, D. He, L. Wang,Towards revealing the mystery behind chain of thought: a theoretical perspective,Advances in Neural Information Processing Systems 36 (2024).
230. Shen et al. [2024]Y. Shen, K. Song, X. Tan, D. Li, W. Lu, Y. Zhuang,Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face,Advances in Neural Information Processing Systems 36 (2024).
231. Khot et al. [2022]T. Khot, H. Trivedi, M. Finlayson, Y. Fu, K. Richardson, P. Clark, A. Sabharwal,Decomposed prompting: A modular approach for solving complex tasks,arXiv preprint arXiv:2210.02406 (2022).
232. Huang et al. [2024]X. Huang, W. Liu, X. Chen, X. Wang, H. Wang, D. Lian, Y. Wang, R. Tang, E. Chen,Understanding the planning of llm agents: A survey,arXiv preprint arXiv:2402.02716 (2024).
233. White et al. [2024]C. White, S. Dooley, M. Roberts, A. Pal, B. Feuer, S. Jain, R. Shwartz-Ziv, N. Jain, K. Saifullah, S. Naidu, et al.,Livebench: A challenging, contamination-free llm benchmark,arXiv preprint arXiv:2406.19314 (2024).
234. Ma et al. [2024]X. Ma, Y. Bhalgat, B. Smart, S. Chen, X. Li, J. Ding, J. Gu, D. Z. Chen, S. Peng, J.-W. Bian, et al.,When llms step into the 3d world: A survey and meta-analysis of 3d tasks via multi-modal large language models,arXiv preprint arXiv:2405.10255 (2024).
235. Du et al. [2022]Y. Du, Z. Liu, J. Li, W. X. Zhao,A survey of vision-language pre-trained models,arXiv preprint arXiv:2202.10936 (2022).
236. Long et al. [2022]S. Long, F. Cao, S. C. Han, H. Yang,Vision-and-language pretrained models: A survey,arXiv preprint arXiv:2204.07356 (2022).
237. Zhou et al. [2022]K. Zhou, J. Yang, C. C. Loy, Z. Liu,Learning to prompt for vision-language models,International Journal of Computer Vision 130 (2022) 2337–2348.
238. Yin et al. [2024]S. Yin, C. Fu, S. Zhao, K. Li, X. Sun, T. Xu, E. Chen,A survey on multimodal large language models,National Science Review (2024) nwae403.
239. Zhang et al. [2024]J. Zhang, J. Huang, S. Jin, S. Lu,Vision-language models for vision tasks: A survey,IEEE Transactions on Pattern Analysis and Machine Intelligence (2024).
240. Yang et al. [2023]Z. Yang, L. Li, K. Lin, J. Wang, C.-C. Lin, Z. Liu, L. Wang,The dawn of lmms: Preliminary explorations with gpt-4v (ision),arXiv preprint arXiv:2309.17421 9 (2023) 1.
241. Islam and Moushi [2024]R. Islam, O. M. Moushi,Gpt-4o: The cutting-edge advancement in multimodal llm,Authorea Preprints (2024).
242. Latif et al. [2024]E. Latif, Y. Zhou, S. Guo, Y. Gao, L. Shi, M. Nayaaba, G. Lee, L. Zhang, A. Bewersdorff, L. Fang, et al.,A systematic assessment of openai o1-preview for higher order thinking in education,arXiv preprint arXiv:2410.21287 (2024).
243. Chiang et al. [2023]W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E. Gonzalez, I. Stoica, E. P. Xing, Vicuna: An open-source chatbot impressing gpt-4 with 90%\* chatgpt quality, 2023. URL: [https://lmsys.org/blog/2023-03-30-vicuna/](https://lmsys.org/blog/2023-03-30-vicuna/).
244. Rizzoli et al. [2023]G. Rizzoli, F. Barbato, M. Caligiuri, P. Zanuttigh,Syndrone-multi-modal uav dataset for urban scenarios,in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023, pp. 2210–2220.
245. Carion et al. [2020]N. Carion, F. Massa, G. Synnaeve, N. Usunier, A. Kirillov, S. Zagoruyko,End-to-end object detection with transformers,in: European conference on computer vision, Springer, 2020, pp. 213–229.
246. Mou et al. [2020]L. Mou, Y. Hua, P. Jin, X. X. Zhu,Era: A data set and deep learning benchmark for event recognition in aerial videos [software and data sets],IEEE Geoscience and Remote Sensing Magazine 8 (2020) 125–133.
247. Bashmal et al. [2023]L. Bashmal, Y. Bazi, M. M. Al Rahhal, M. Zuair, F. Melgani,Capera: Captioning events in aerial videos,Remote Sensing 15 (2023) 2139.
248. Jaisawal et al. [2024]P. K. Jaisawal, S. Papakonstantinou, V. Gollnick,Airfisheye dataset: A multi-model fisheye dataset for uav applications,in: 2024 IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2024, pp. 11818–11824.
249. Florea et al. [2021]H. Florea, V.-C. Miclea, S. Nedevschi,Wilduav: Monocular uav dataset for depth estimation tasks,in: 2021 IEEE 17th International Conference on Intelligent Computer Communication and Processing (ICCP), IEEE, 2021, pp. 291–298.
250. Oh et al. [2011]S. Oh, A. Hoogs, A. Perera, N. Cuntoor, C.-C. Chen, J. T. Lee, S. Mukherjee, J. Aggarwal, H. Lee, L. Davis, et al.,A large-scale benchmark dataset for event recognition in surveillance video,in: CVPR 2011, IEEE, 2011, pp. 3153–3160.
251. Zhang et al. [2022]C. Zhang, G. Huang, L. Liu, S. Huang, Y. Yang, X. Wan, S. Ge, D. Tao,Webuav-3m: A benchmark for unveiling the power of million-scale deep uav tracking,IEEE Transactions on Pattern Analysis and Machine Intelligence 45 (2022) 9186–9205.
252. Li et al. [2022]B. Li, C. Fu, F. Ding, J. Ye, F. Lin,All-day object tracking for unmanned aerial vehicle,IEEE Transactions on Mobile Computing 22 (2022) 4515–4529.
253. Zhang et al. [2022]P. Zhang, J. Zhao, D. Wang, H. Lu, X. Ruan,Visible-thermal uav tracking: A large-scale benchmark and new baseline,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 8886–8895.
254. Wang et al. [2021]X. Wang, X. Shu, Z. Zhang, B. Jiang, Y. Wang, Y. Tian, F. Wu,Towards more flexible and accurate object tracking with natural language: Algorithms and benchmark,in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2021, pp. 13763–13773.
255. Zhang et al. [2020]S. Zhang, Q. Zhang, Y. Yang, X. Wei, P. Wang, B. Jiao, Y. Zhang,Person re-identification in aerial imagery,IEEE Transactions on Multimedia 23 (2020) 281–291.
256. Kristan et al. [2020]M. Kristan, A. Leonardis, J. Matas, M. Felsberg, R. Pflugfelder, J.-K. Kämäräinen, M. Danelljan, L. Č. Zajc, A. Lukežič, O. Drbohlav, et al.,The eighth visual object tracking vot2020 challenge results,in: Computer Vision–ECCV 2020 Workshops: Glasgow, UK, August 23–28, 2020, Proceedings, Part V 16, Springer, 2020, pp. 547–601.
257. Huang et al. [2019]L. Huang, X. Zhao, K. Huang,Got-10k: A large high-diversity benchmark for generic object tracking in the wild,IEEE transactions on pattern analysis and machine intelligence 43 (2019) 1562–1577.
258. Li and Yeung [2017]S. Li, D.-Y. Yeung,Visual object tracking for unmanned aerial vehicles: A benchmark and new motion models,in: Proceedings of the AAAI Conference on Artificial Intelligence, volume 31, 2017.
259. Robicquet et al. [2016]A. Robicquet, A. Sadeghian, A. Alahi, S. Savarese,Learning social etiquette: Human trajectory understanding in crowded scenes,in: Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VIII 14, Springer, 2016, pp. 549–565.
260. Mundhenk et al. [2016]T. N. Mundhenk, G. Konjevod, W. A. Sakla, K. Boakye,A large contextual dataset for classification, detection and counting of cars with deep learning,in: Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part III 14, Springer, 2016, pp. 785–800.
261. Kapoor et al. [2023]S. Kapoor, A. Sharma, A. Verma, S. Singh,Aeriform in-action: A novel dataset for human action recognition in aerial videos,Pattern Recognition 140 (2023) 109505.
262. Corona et al. [2021]K. Corona, K. Osterdahl, R. Collins, A. Hoogs,Meva: A large-scale multiview, multimodal video dataset for activity detection,in: Proceedings of the IEEE/CVF winter conference on applications of computer vision, 2021, pp. 1060–1068.
263. Perera et al. [2020]A. G. Perera, Y. W. Law, T. T. Ogunwa, J. Chahl,A multiviewpoint outdoor dataset for human action recognition,IEEE Transactions on Human-Machine Systems 50 (2020) 405–413.
264. Choi et al. [2020]J. Choi, G. Sharma, M. Chandraker, J.-B. Huang,Unsupervised and semi-supervised domain adaptation for action recognition from drones,in: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2020, pp. 1717–1726.
265. Perera et al. [2019]A. G. Perera, Y. W. Law, J. Chahl,Drone-action: An outdoor recorded drone video dataset for action recognition,Drones 3 (2019) 82.
266. Perera et al. [2018]A. G. Perera, Y. Wei Law, J. Chahl,Uav-gesture: A dataset for uav control and gesture recognition,in: Proceedings of the European Conference on Computer Vision (ECCV) Workshops, 2018, pp. 0–0.
267. Lee et al. [2024]J. Lee, T. Miyanishi, S. Kurita, K. Sakamoto, D. Azuma, Y. Matsuo, N. Inoue,Citynav: Language-goal aerial navigation dataset with geographic information,arXiv preprint arXiv:2406.14240 (2024).
268. Liu et al. [2023]S. Liu, H. Zhang, Y. Qi, P. Wang, Y. Zhang, Q. Wu,Aerialvln: Vision-and-language navigation for uavs,in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023, pp. 15384–15394.
269. Zhu et al. [2021]S. Zhu, T. Yang, C. Chen,Vigor: Cross-view image geo-localization beyond one-to-one retrieval,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 3640–3649.
270. Zheng et al. [2020]Z. Zheng, Y. Wei, Y. Yang,University-1652: A multi-view multi-source benchmark for drone-based geo-localization,in: Proceedings of the 28th ACM international conference on Multimedia, 2020, pp. 1395–1403.
271. Yao et al. [2024]Y. Yao, S. Luo, H. Zhao, G. Deng, L. Song,Can llm substitute human labeling? a case study of fine-grained chinese address entity recognition dataset for uav delivery,in: Companion Proceedings of the ACM on Web Conference 2024, 2024, pp. 1099–1102.
272. Dai et al. [2023]M. Dai, E. Zheng, Z. Feng, L. Qi, J. Zhuang, W. Yang,Vision-based uav self-positioning in low-altitude urban environments,IEEE Transactions on Image Processing (2023).
273. Schumann and Riezler [2022]R. Schumann, S. Riezler,Analyzing generalization of vision and language navigation to unseen outdoor areas,arXiv preprint arXiv:2203.13838 (2022).
274. Zhang et al. [2025]G. Zhang, Y. Liu, X. Yang, H. Huang, C. Huang,Trafficnight: An aerial multimodal benchmark for nighttime vehicle surveillance,in: European Conference on Computer Vision, Springer, 2025, pp. 36–48.
275. Zhu et al. [2021]P. Zhu, L. Wen, D. Du, X. Bian, H. Fan, Q. Hu, H. Ling,Detection and tracking meet drones challenge,IEEE Transactions on Pattern Analysis and Machine Intelligence 44 (2021) 7380–7399.
276. Shah et al. [2018]A. P. Shah, J.-B. Lamare, T. Nguyen-Anh, A. Hauptmann,Cadp: A novel dataset for cctv traffic camera based accident analysis,in: 2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), IEEE, 2018, pp. 1–9.
277. Hsieh et al. [2017]M.-R. Hsieh, Y.-L. Lin, W. H. Hsu,Drone-based object counting by spatially regularized regional proposal network,in: Proceedings of the IEEE international conference on computer vision, 2017, pp. 4145–4153.
278. Waqas Zamir et al. [2019]S. Waqas Zamir, A. Arora, A. Gupta, S. Khan, G. Sun, F. Shahbaz Khan, F. Zhu, L. Shao, G.-S. Xia, X. Bai,isaid: A large-scale dataset for instance segmentation in aerial images,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, 2019, pp. 28–37.
279. Yang et al. [2018]M. Y. Yang, W. Liao, X. Li, B. Rosenhahn,Deep learning for vehicle detection in aerial images,in: 2018 25th IEEE International Conference on Image Processing (ICIP), IEEE, 2018, pp. 3079–3083.
280. Lyu et al. [2020]Y. Lyu, G. Vosselman, G.-S. Xia, A. Yilmaz, M. Y. Yang,Uavid: A semantic segmentation dataset for uav imagery,ISPRS journal of photogrammetry and remote sensing 165 (2020) 108–119.
281. Bozcan and Kayacan [2020]I. Bozcan, E. Kayacan,Au-air: A multi-modal unmanned aerial vehicle dataset for low altitude traffic surveillance,in: 2020 IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2020, pp. 8504–8510.
282. Krajewski et al. [2018]R. Krajewski, J. Bock, L. Kloeker, L. Eckstein,The highd dataset: A drone dataset of naturalistic vehicle trajectories on german highways for validation of highly automated driving systems,in: 2018 21st international conference on intelligent transportation systems (ITSC), IEEE, 2018, pp. 2118–2125.
283. Du et al. [2018]D. Du, Y. Qi, H. Yu, Y. Yang, K. Duan, G. Li, W. Zhang, Q. Huang, Q. Tian,The unmanned aerial vehicle benchmark: Object detection and tracking,in: Proceedings of the European conference on computer vision (ECCV), 2018, pp. 370–386.
284. Razakarivony and Jurie [2016]S. Razakarivony, F. Jurie,Vehicle detection in aerial imagery: A small target detection benchmark,Journal of Visual Communication and Image Representation 34 (2016) 187–203.
285. Lam et al. [2018]D. Lam, R. Kuzma, K. McGee, S. Dooley, M. Laielli, M. Klaric, Y. Bulatov, B. McCord,xview: Objects in context in overhead imagery,arXiv preprint arXiv:1802.07856 (2018).
286. Xia et al. [2018]G.-S. Xia, X. Bai, J. Ding, Z. Zhu, S. Belongie, J. Luo, M. Datcu, M. Pelillo, L. Zhang,Dota: A large-scale dataset for object detection in aerial images,in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 3974–3983.
287. Lu et al. [2017]X. Lu, B. Wang, X. Zheng, X. Li,Exploring models and data for remote sensing image caption generation,IEEE Transactions on Geoscience and Remote Sensing 56 (2017) 2183–2195.
288. Liu et al. [2024]F. Liu, D. Chen, Z. Guan, X. Zhou, J. Zhu, Q. Ye, L. Fu, J. Zhou,Remoteclip: A vision language foundation model for remote sensing,IEEE Transactions on Geoscience and Remote Sensing (2024).
289. Li et al. [2020]K. Li, G. Wan, G. Cheng, L. Meng, J. Han,Object detection in optical remote sensing images: A survey and a new benchmark,ISPRS journal of photogrammetry and remote sensing 159 (2020) 296–307.
290. Zhang et al. [2019]Y. Zhang, Y. Yuan, Y. Feng, X. Lu,Hierarchical and robust convolutional neural network for very high-resolution remote sensing object detection,IEEE Transactions on Geoscience and Remote Sensing 57 (2019) 5535–5548.
291. Liu et al. [2017]Z. Liu, L. Yuan, L. Weng, Y. Yang,A high resolution optical satellite image dataset for ship recognition and some new baselines,in: International conference on pattern recognition applications and methods, volume 2, SciTePress, 2017, pp. 324–331.
292. Long et al. [2017]Y. Long, Y. Gong, Z. Xiao, Q. Liu,Accurate object localization in remote sensing images based on convolutional neural networks,IEEE Transactions on Geoscience and Remote Sensing 55 (2017) 2486–2498.
293. Cheng et al. [2017]G. Cheng, J. Han, X. Lu,Remote sensing image scene classification: Benchmark and state of the art,Proceedings of the IEEE 105 (2017) 1865–1883.
294. Cheng et al. [2014]G. Cheng, J. Han, P. Zhou, L. Guo,Multi-class geospatial object detection and geographic image classification based on collection of part detectors,ISPRS Journal of Photogrammetry and Remote Sensing 98 (2014) 119–132.
295. Amraoui et al. [2022]K. E. Amraoui, M. Lghoul, A. Ezzaki, L. Masmoudi, M. Hadri, H. Elbelrhiti, A. A. Simo,Avo-airdb: An avocado uav database for agricultural image segmentation and classification,Data in Brief 45 (2022) 108738.
296. Raptis et al. [2023]E. K. Raptis, M. Krestenitis, K. Egglezos, O. Kypris, K. Ioannidis, L. Doitsidis, A. C. Kapoutsis, S. Vrochidis, I. Kompatsiaris, E. B. Kosmatopoulos,End-to-end precision agriculture uav-based functionalities tailored to field characteristics,Journal of Intelligent & Robotic Systems 107 (2023) 23.
297. Tetila et al. [2024]E. C. Tetila, B. L. Moro, G. Astolfi, A. B. da Costa, W. P. Amorim, N. A. de Souza Belete, H. Pistori, J. G. A. Barbedo,Real-time detection of weeds by species in soybean using uav images,Crop Protection 184 (2024) 106846.
298. Ödübek and Atik [2024]E. Ödübek, M. E. Atik,Detection of asphalt pavement cracks with yolo architectures from unmanned aerial vehicle images,in: 2024 32nd Signal Processing and Communications Applications Conference (SIU), IEEE, 2024, pp. 1–4.
299. Vieira e Silva et al. [2023]A. L. B. Vieira e Silva, H. de Castro Felix, F. P. M. Simões, V. Teichrieb, M. dos Santos, H. Santiago, V. Sgotti, H. Lott Neto,Insplad: A dataset and benchmark for power line asset inspection in uav images,International journal of remote sensing 44 (2023) 7294–7320.
300. Mishra et al. [2020]B. Mishra, D. Garg, P. Narang, V. Mishra,Drone-surveillance for search and rescue in natural disaster,Computer Communications 156 (2020) 1–10.
301. Wang and Mahmoudian [2023]Z. Wang, N. Mahmoudian,Aerial fluvial image dataset for deep semantic segmentation neural networks and its benchmarks,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 16 (2023) 4755–4766.
302. Rahnemoonfar et al. [2021]M. Rahnemoonfar, T. Chowdhury, A. Sarkar, D. Varshney, M. Yari, R. R. Murphy,Floodnet: A high resolution aerial imagery dataset for post flood scene understanding,IEEE Access 9 (2021) 89644–89654.
303. Pan et al. [2024]L. Pan, C. Song, X. Gan, K. Xu, Y. Xie,Military image captioning for low-altitude uav or ugv perspectives,Drones 8 (2024) 421.
304. Mou et al. [2023]C. Mou, T. Liu, C. Zhu, X. Cui,Waid: A large-scale dataset for wildlife detection with drones,Applied Sciences 13 (2023) 10397.
305. Shah et al. [2018]S. Shah, D. Dey, C. Lovett, A. Kapoor,Airsim: High-fidelity visual and physical simulation for autonomous vehicles,in: Field and Service Robotics: Results of the 11th International Conference, Springer, 2018, pp. 621–635.
306. Dosovitskiy et al. [2017]A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, V. Koltun,Carla: An open urban driving simulator,in: Conference on robot learning, PMLR, 2017, pp. 1–16.
307. NVIDIA [2024]NVIDIA, Isaac sim robotics simulator, 2024. URL: [https://developer.nvidia.com/isaac/sim](https://developer.nvidia.com/isaac/sim), accessed: 2024-11-01.
308. Gao et al. [2024]C. Gao, B. Zhao, W. Zhang, J. Zhang, J. Mao, Z. Zheng, F. Man, J. Fang, Z. Zhou, J. Cui, X. Chen, Y. Li,Embodiedcity: A benchmark platform for embodied agent in real-world city environment,arXiv preprint (2024).
309. Zhang et al. [2021]C. Zhang, S. Bengio, M. Hardt, B. Recht, O. Vinyals,Understanding deep learning (still) requires rethinking generalization,Communications of the ACM 64 (2021) 107–115.
310. Crawshaw [2020]M. Crawshaw,Multi-task learning with deep neural networks: A survey,arXiv preprint arXiv:2009.09796 (2020).
311. Gehrmann et al. [2019]S. Gehrmann, H. Strobelt, R. Krüger, H. Pfister, A. M. Rush,Visual interaction with deep learning models through collaborative semantic inference,IEEE transactions on visualization and computer graphics 26 (2019) 884–894.
312. Li et al. [2024]H. Li, X. Liu, G. Li,A benchmark for uav-view natural language-guided tracking,Electronics 13 (2024) 1706.
313. Ma et al. [2024]Z. Ma, Y. Li, R. Ma, C. Liang,Unsupervised semantic segmentation of high-resolution uav imagery for road scene parsing,arXiv preprint arXiv:2402.02985 (2024).
314. Limberg et al. [2024]C. Limberg, A. Gonçalves, B. Rigault, H. Prendinger,Leveraging yolo-world and gpt-4v lmms for zero-shot person detection and action recognition in drone imagery,arXiv preprint arXiv:2404.01571 (2024).
315. Kim et al. [2024]H. Kim, D. Lee, S. Park, Y. M. Ro,Weather-aware drone-view object detection via environmental context understanding,in: 2024 IEEE International Conference on Image Processing (ICIP), IEEE, 2024, pp. 549–555.
316. Sakaino [2023]H. Sakaino,Dynamic texts from uav perspective natural images,in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023, pp. 2070–2081.
317. Liang et al. [2023]F. Liang, B. Wu, X. Dai, K. Li, Y. Zhao, H. Zhang, P. Zhang, P. Vajda, D. Marculescu,Open-vocabulary semantic segmentation with mask-adapted clip,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp. 7061–7070.
318. Gu et al. [2021]X. Gu, T.-Y. Lin, W. Kuo, Y. Cui,Open-vocabulary object detection via vision and language knowledge distillation,arXiv preprint arXiv:2104.13921 (2021).
319. Gong et al. [2024]Z. Gong, Z. Wei, D. Wang, X. Ma, H. Chen, Y. Jia, Y. Deng, Z. Ji, X. Zhu, N. Yokoya, et al.,Crossearth: Geospatial vision foundation model for domain generalizable remote sensing semantic segmentation,arXiv preprint arXiv:2410.22629 (2024).
320. Florea and Nedevschi [2024]H. Florea, S. Nedevschi,Tandepth: Leveraging global dems for metric monocular depth estimation in uavs,arXiv preprint arXiv:2409.05142 (2024).
321. de Zarzà et al. [2023]I. de Zarzà, J. de Curtò, C. T. Calafate,Socratic video understanding on unmanned aerial vehicles,Procedia Computer Science 225 (2023) 144–154.
322. Zhao et al. [2023]H. Zhao, F. Pan, H. Ping, Y. Zhou,Agent as cerebrum, controller as cerebellum: Implementing an embodied lmm-based agent on drones,arXiv preprint arXiv:2311.15033 (2023).
323. Bazi et al. [2024]Y. Bazi, L. Bashmal, M. M. Al Rahhal, R. Ricci, F. Melgani,Rs-llava: A large vision-language model for joint captioning and question answering in remote sensing imagery,Remote Sensing 16 (2024) 1477.
324. Zhang et al. [2024]Z. Zhang, T. Zhao, Y. Guo, J. Yin,Rs5m and georsclip: A large scale vision-language dataset and a large vision-language model for remote sensing,IEEE Transactions on Geoscience and Remote Sensing (2024).
325. Zhan et al. [2024]Y. Zhan, Z. Xiong, Y. Yuan,Skyeyegpt: Unifying remote sensing vision-language tasks via instruction tuning with large language model,arXiv preprint arXiv:2401.09712 (2024).
326. Zhang et al. [2024]J. Zhang, K. Wang, R. Xu, G. Zhou, Y. Hong, X. Fang, Q. Wu, Z. Zhang, H. Wang,Navid: Video-based vlm plans the next step for vision-and-language navigation,arXiv preprint arXiv:2402.15852 (2024).
327. Hong et al. [2024]H. Hong, S. Wang, Z. Huang, Q. Wu, J. Liu,Why only text: Empowering vision-and-language navigation with multi-modal prompts,arXiv preprint arXiv:2406.02208 (2024).
328. Gao et al. [2024]Y. Gao, Z. Wang, L. Jing, D. Wang, X. Li, B. Zhao,Aerial vision-and-language navigation via semantic-topo-metric representation guided llm reasoning,arXiv preprint arXiv:2410.08500 (2024).
329. Wang et al. [2024]X. Wang, D. Yang, Z. Wang, H. Kwan, J. Chen, W. Wu, H. Li, Y. Liao, S. Liu,Towards realistic uav vision-language navigation: Platform, benchmark, and methodology,arXiv preprint arXiv:2410.07087 (2024).
330. Sanyal and Roy [2024]S. Sanyal, K. Roy,Asma: An adaptive safety margin algorithm for vision-language drone navigation via scene-aware control barrier functions,arXiv preprint arXiv:2409.10283 (2024).
331. Zhang et al. [2024]W. Zhang, Y. Liu, X. Wang, X. Chen, C. Gao, X. Chen,Demo abstract: Embodied aerial agent for city-level visual language navigation using large language model,in: 2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN), IEEE, 2024, pp. 265–266.
332. Chen et al. [2023]Z. Chen, J. Li, F. Fukumoto, P. Liu, Y. Suzuki,Vision-language navigation for quadcopters with conditional transformer and prompt-based text rephraser,in: Proceedings of the 5th ACM International Conference on Multimedia in Asia, 2023, pp. 1–7.
333. Blei et al. [2024]Y. Blei, M. Krawez, N. Nilavadi, T. K. Kaiser, W. Burgard,Cloudtrack: Scalable uav tracking with cloud semantics,arXiv preprint arXiv:2409.16111 (2024).
334. Cai et al. [2024]Z. Cai, C. R. Cardenas, K. Leo, C. Zhang, K. Backman, H. Li, B. Li, M. Ghorbanali, S. Datta, L. Qu, et al.,Neusis: A compositional neuro-symbolic framework for autonomous perception, reasoning, and planning in complex uav search missions,arXiv preprint arXiv:2409.10196 (2024).
335. Döschl and Kiam [2024]B. Döschl, J. J. Kiam,Say-reapex: An llm-modulo uav online planning framework for search and rescue,in: 2nd CoRL Workshop on Learning Effective Abstractions for Planning, 2024.
336. Ravichandran et al. [2024]Z. Ravichandran, V. Murali, M. Tzes, G. J. Pappas, V. Kumar,Spine: Online semantic planning for missions with incomplete natural language specifications in unstructured environments,arXiv preprint arXiv:2410.03035 (2024).
337. Aikins et al. [2024]G. Aikins, M. P. Dao, K. J. Moukpe, T. C. Eskridge, K.-D. Nguyen,Leviosa: Natural language-based uncrewed aerial vehicle trajectory generation,Electronics 13 (2024) 4508.
338. Cui et al. [2024]J. Cui, G. Liu, H. Wang, Y. Yu, J. Yang,Tpml: Task planning for multi-uav system with large language models,in: 2024 IEEE 18th International Conference on Control & Automation (ICCA), IEEE, 2024, pp. 886–891.
339. pen [2023]PCL. Peng Cheng Mind. Accessed: 2023-02-08, 2023. URL: [https://openi.pcl.ac.cn/PengChengMind/PengCheng.Mind](https://openi.pcl.ac.cn/PengChengMind/PengCheng.Mind).
340. Liu et al. [2024]Y. Liu, Z. Zhou, J. Liu, L. Chen, J. Wang,Multi-agent formation control using large language models,Authorea Preprints (2024).
341. Vemprala et al. [2024]S. H. Vemprala, R. Bonatti, A. Bucker, A. Kapoor,Chatgpt for robotics: Design principles and model abilities,IEEE Access (2024).
342. Zhong et al. [2024]J. Zhong, M. Li, Y. Chen, Z. Wei, F. Yang, H. Shen,A safer vision-based autonomous planning system for quadrotor uavs with dynamic obstacle trajectory prediction and its application with llms,in: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2024, pp. 920–929.
343. TAZIR et al. [2023]M. L. TAZIR, M. MANCAS, T. DUTOIT,From words to flight: Integrating openai chatgpt with px4/gazebo for natural language-based drone control,in: International Workshop on Computer Science and Engineering, 2023.
344. Phadke et al. [2024]A. Phadke, A. Hadimlioglu, T. Chu, C. N. Sekharan,Integrating large language models for uav control in simulated environments: A modular interaction approach,arXiv preprint arXiv:2410.17602 (2024).
345. Liu et al. [2024]G. Liu, T. Sun, W. Li, X. Li, X. Liu, J. Cui,Eai-sim: An open-source embodied ai simulation framework with large language models,in: 2024 IEEE 18th International Conference on Control & Automation (ICCA), IEEE, 2024, pp. 994–999.
346. Zhu et al. [2024]T. Zhu, W. Newton, S. Embury, Y. Sun,Taiist cps-uav at the sbft tool competition 2024,in: Proceedings of the 17th ACM/IEEE International Workshop on Search-Based and Fuzz Testing, 2024, pp. 51–52.
347. Jiao et al. [2023]A. Jiao, T. P. Patel, S. Khurana, A.-M. Korol, L. Brunke, V. K. Adajania, U. Culha, S. Zhou, A. P. Schoellig,Swarm-gpt: Combining large language models with safe motion planning for robot choreography design,arXiv preprint arXiv:2312.01059 (2023).
348. Lykov et al. [2024]A. Lykov, S. Karaf, M. Martynov, V. Serpiva, A. Fedoseev, M. Konenkov, D. Tsetserukou,Flockgpt: Guiding uav flocking with linguistic orchestration,arXiv preprint arXiv:2405.05872 (2024).
349. Pueyo et al. [2024]P. Pueyo, E. Montijano, A. C. Murillo, M. Schwager,Clipswarm: Generating drone shows from text prompts with vision-language models,arXiv preprint arXiv:2403.13467 (2024).
350. Li et al. [2024]X. Li, X. Feng, S. Hu, M. Wu, D. Zhang, J. Zhang, K. Huang,Dtllm-vlt: Diverse text generation for visual language tracking based on llm,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 7283–7292.
351. Arrabi et al. [2024]A. Arrabi, X. Zhang, W. Sultani, C. Chen, S. Wshah,Cross-view meets diffusion: Aerial image synthesis with geometry and text guidance,arXiv preprint arXiv:2408.04224 (2024).
352. Yao et al. [2024]F. Yao, Y. Yue, Y. Liu, X. Sun, K. Fu,Aeroverse: Uav-agent benchmark suite for simulating, pre-training, finetuning, and evaluating aerospace embodied world models,arXiv preprint arXiv:2408.15511 (2024).
353. Tang et al. [2024]Y.-C. Tang, P.-Y. Chen, T.-Y. Ho,Defining and evaluating physical safety for large language models,arXiv preprint arXiv:2411.02317 (2024).
354. Xu et al. [2024]Y. Xu, Z. Jian, J. Zha, X. Chen,Emergency networking using uavs: A reinforcement learning approach with large language model,in: 2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN), IEEE, 2024, pp. 281–282.
355. Xiang et al. [2024]X. Xiang, J. Xue, L. Zhao, Y. Lei, C. Yue, K. Lu,Real-time integration of fine-tuned large language model for improved decision-making in reinforcement learning,in: 2024 International Joint Conference on Neural Networks (IJCNN), IEEE, 2024, pp. 1–8.
356. Pineli Simões et al. [2024]L. E. Pineli Simões, L. Brandão Rodrigues, R. Mota Silva, G. Rodrigues da Silva,Evaluating voice command pipelines for drone control: From stt and llm to direct classification and siamese networks,arXiv e-prints (2024) arXiv–2407.
357. Huang et al. [2022]Y. Huang, J. Chen, D. Huang,Ufpmp-det: Toward accurate and efficient object detection on drone imagery,in: Proceedings of the AAAI conference on artificial intelligence, volume 36, 2022, pp. 1026–1033.
358. Zhu et al. [2021]X. Zhu, S. Lyu, X. Wang, Q. Zhao,Tph-yolov5: Improved yolov5 based on transformer prediction head for object detection on drone-captured scenarios,in: Proceedings of the IEEE/CVF international conference on computer vision, 2021, pp. 2778–2788.
359. Fu et al. [2023]X. Fu, G. Wei, X. Yuan, Y. Liang, Y. Bo,Efficient yolov7-drone: an enhanced object detection approach for drone aerial imagery,Drones 7 (2023) 616.
360. Yang et al. [2020]W. Yang, Y. Yuan, W. Ren, J. Liu, W. J. Scheirer, Z. Wang, T. Zhang, Q. Zhong, D. Xie, S. Pu, et al.,Advancing image understanding in poor visibility environments: A collective benchmark study,IEEE Transactions on Image Processing 29 (2020) 5737–5752.
361. Tan et al. [2021]L. Tan, X. Lv, X. Lian, G. Wang,Yolov4\_drone: Uav image target detection based on an improved yolov4 algorithm,Computers & Electrical Engineering 93 (2021) 107261.
362. Fang et al. [2023]W. Fang, G. Zhang, Y. Zheng, Y. Chen,Multi-task learning for uav aerial object detection in foggy weather condition,Remote Sensing 15 (2023) 4617.
363. Hoanh and Pham [2024]N. Hoanh, T. V. Pham,A multi-task framework for car detection from high-resolution uav imagery focusing on road regions,IEEE Transactions on Intelligent Transportation Systems (2024).
364. Jing et al. [2022]H. Jing, Y. Cheng, H. Wu, H. Wang,Radar target detection with multi-task learning in heterogeneous environment,IEEE Geoscience and Remote Sensing Letters 19 (2022) 1–5.
365. Qu et al. [2024]H. Qu, Y. Cai, J. Liu,Llms are good action recognizers,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 18395–18406.
366. Han and Lim [2024]G. Han, S.-N. Lim,Few-shot object detection with foundation models,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 28608–28618.
367. Lin et al. [2024]C. Lin, Y. Jiang, L. Qu, Z. Yuan, J. Cai,Generative region-language pretraining for open-ended object detection,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 13958–13968.
368. Zang et al. [2024]Y. Zang, W. Li, J. Han, K. Zhou, C. C. Loy,Contextual object detection with multimodal large language models,International Journal of Computer Vision (2024) 1–19.
369. Yang et al. [2024]F. Yang, S. Zhao, Y. Zhang, H. Chen, H. Chen, W. Tang, H. Lu, P. Xu, Z. Yang, J. Han, et al.,Llmi3d: Empowering llm with 3d perception from a single 2d image,arXiv preprint arXiv:2408.07422 (2024).
370. Huang et al. [2023]L. Huang, W. Yu, W. Ma, W. Zhong, Z. Feng, H. Wang, Q. Chen, W. Peng, X. Feng, B. Qin, et al.,A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions,ACM Transactions on Information Systems (2023).
371. Liu et al. [2024]H. Liu, W. Xue, Y. Chen, D. Chen, X. Zhao, K. Wang, L. Hou, R. Li, W. Peng,A survey on hallucination in large vision-language models,arXiv preprint arXiv:2402.00253 (2024).
372. Favero et al. [2024]A. Favero, L. Zancato, M. Trager, S. Choudhary, P. Perera, A. Achille, A. Swaminathan, S. Soatto,Multi-modal hallucination control by visual information grounding,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 14303–14312.
373. Zhao et al. [2021]Q. Zhao, J. Liu, Y. Li, H. Zhang,Semantic segmentation with attention mechanism for remote sensing images,IEEE Transactions on Geoscience and Remote Sensing 60 (2021) 1–13.
374. Yuan et al. [2021]X. Yuan, J. Shi, L. Gu,A review of deep learning methods for semantic segmentation of remote sensing imagery,Expert Systems with Applications 169 (2021) 114417.
375. Cai et al. [2022]Y. Cai, Y. Yang, Y. Shang, Z. Chen, Z. Shen, J. Yin,Iterdanet: Iterative intra-domain adaptation for semantic segmentation of remote sensing images,IEEE Transactions on Geoscience and Remote Sensing 60 (2022) 1–17.
376. Bai et al. [2022]L. Bai, S. Du, X. Zhang, H. Wang, B. Liu, S. Ouyang,Domain adaptation for remote sensing image semantic segmentation: An integrated approach of contrastive learning and adversarial learning,IEEE Transactions on Geoscience and Remote Sensing 60 (2022) 1–13.
377. He et al. [2016]K. He, X. Zhang, S. Ren, J. Sun,Deep residual learning for image recognition,in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770–778.
378. Li et al. [2024]L. Li, Y. Zhang, Z. Jiang, Z. Wang, L. Zhang, H. Gao,Unmanned aerial vehicle-neural radiance field (uav-nerf): Learning multiview drone three-dimensional reconstruction with neural radiance field,Remote Sensing 16 (2024) 4168.
379. Wu et al. [2024]Y. Wu, J. Liu, S. Ji,3d gaussian splatting for large-scale surface reconstruction from aerial images,arXiv preprint arXiv:2409.00381 (2024).
380. Florea and Nedevschi [2022]H. Florea, S. Nedevschi,Survey on monocular depth estimation for unmanned aerial vehicles using deep learning,in: 2022 IEEE 18th International Conference on Intelligent Computer Communication and Processing (ICCP), IEEE, 2022, pp. 319–326.
381. Chang et al. [2023]R. Chang, K. Yu, Y. Yang,Self-supervised monocular depth estimation using global and local mixed multi-scale feature enhancement network for low-altitude uav remote sensing,Remote Sensing 15 (2023) 3275.
382. Yu et al. [2023]K. Yu, H. Li, L. Xing, T. Wen, D. Fu, Y. Yang, C. Zhou, R. Chang, S. Zhao, L. Xing, et al.,Scene-aware refinement network for unsupervised monocular depth estimation in ultra-low altitude oblique photography of uav,ISPRS Journal of Photogrammetry and Remote Sensing 205 (2023) 284–300.
383. Antol et al. [2015]S. Antol, A. Agrawal, J. Lu, M. Mitchell, D. Batra, C. L. Zitnick, D. Parikh,Vqa: Visual question answering,in: Proceedings of the IEEE international conference on computer vision, 2015, pp. 2425–2433.
384. Goyal et al. [2017]Y. Goyal, T. Khot, D. Summers-Stay, D. Batra, D. Parikh,Making the v in vqa matter: Elevating the role of image understanding in visual question answering,in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 6904–6913.
385. Zhou et al. [2020]L. Zhou, H. Palangi, L. Zhang, H. Hu, J. Corso, J. Gao,Unified vision-language pre-training for image captioning and vqa,in: Proceedings of the AAAI conference on artificial intelligence, volume 34, 2020, pp. 13041–13049.
386. Hu et al. [2022]X. Hu, Z. Gan, J. Wang, Z. Yang, Z. Liu, Y. Lu, L. Wang,Scaling up vision-language pre-training for image captioning,in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2022, pp. 17980–17989.
387. Wang et al. [2023]X. Wang, X. Cui, D. Li, F. Liu, L. Jiao,Multi-model fusion for aerial vision and dialog navigation based on human attention aids,arXiv preprint arXiv:2308.14064 (2023).
388. Chu et al. [2025]M. Chu, Z. Zheng, W. Ji, T. Wang, T.-S. Chua,Towards natural language-guided drones: Geotext-1652 benchmark with spatial relation matching,in: European Conference on Computer Vision, Springer, 2025, pp. 213–231.
389. Zhang et al. [2023]L. Zhang, A. Rao, M. Agrawala,Adding conditional control to text-to-image diffusion models,in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023, pp. 3836–3847.
390. Liu et al. [2024]R. Liu, W. Wang, Y. Yang,Volumetric environment representation for vision-language navigation,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 16317–16328.
391. Li et al. [2024]X. Li, S. Hu, X. Feng, D. Zhang, M. Wu, J. Zhang, K. Huang,Dtvlt: A multi-modal diverse text benchmark for visual language tracking based on llm,arXiv preprint arXiv:2410.02492 (2024).
392. Sun et al. [2024]L. Sun, X. Li, Z. Yang, D. Gao,Visual object tracking based on the motion prediction and block search in uav videos,Drones 8 (2024) 252.
393. Wu et al. [2019]C. Wu, B. Ju, Y. Wu, X. Lin, N. Xiong, G. Xu, H. Li, X. Liang,Uav autonomous target search based on deep reinforcement learning in complex disaster scene,IEEE Access 7 (2019) 117227–117245.
394. Hou et al. [2023]Y. Hou, J. Zhao, R. Zhang, X. Cheng, L. Yang,Uav swarm cooperative target search: A multi-agent reinforcement learning approach,IEEE Transactions on Intelligent Vehicles (2023).
395. Bethke et al. [2008]B. Bethke, M. Valenti, J. P. How,Uav task assignment,IEEE robotics & automation magazine 15 (2008) 39–44.
396. Zhou et al. [2018]Z. Zhou, J. Feng, B. Gu, B. Ai, S. Mumtaz, J. Rodriguez, M. Guizani,When mobile crowd sensing meets uav: Energy-efficient task assignment and route planning,IEEE Transactions on Communications 66 (2018) 5526–5538.
397. Mao et al. [2024]X. Mao, G. Wu, M. Fan, Z. Cao, W. Pedrycz,Dl-drl: A double-level deep reinforcement learning approach for large-scale task scheduling of multi-uav,IEEE Transactions on Automation Science and Engineering (2024).
398. Tejaswi and Lee [2022]K. Tejaswi, T. Lee,Constrained imitation learning for a flapping wing unmanned aerial vehicle,IEEE Robotics and Automation Letters 7 (2022) 10534–10541.
399. Shukla et al. [2020]D. Shukla, S. Keshmiri, N. Beckage,Imitation learning for neural network autopilot in fixed-wing unmanned aerial systems,in: 2020 International Conference on Unmanned Aircraft Systems (ICUAS), IEEE, 2020, pp. 1508–1517.
400. Choi and Ahn [2020]U. Choi, J. Ahn,Imitation learning-based unmanned aerial vehicle planning for multitarget reconnaissance under uncertainty,Journal of Aerospace Information Systems 17 (2020) 36–50.
401. Liang et al. [2023]Z. Liang, Q. Li, G. Fu,Multi-uav collaborative search and attack mission decision-making in unknown environments,Sensors 23 (2023) 7398.
402. Wang and Wang [2024]H. Wang, J. Wang,Enhancing multi-uav air combat decision making via hierarchical reinforcement learning,Scientific Reports 14 (2024) 4458.
403. Du et al. [2024]Y. Du, N. Qi, X. Li, M. Xiao, A.-A. A. Boulogeorgos, T. A. Tsiftsis, Q. Wu,Distributed multi-uav trajectory planning for downlink transmission: a gnn-enhanced drl approach,IEEE Wireless Communications Letters (2024).
404. Li et al. [2022]K. Li, W. Ni, X. Yuan, A. Noor, A. Jamalipour,Deep-graph-based reinforcement learning for joint cruise control and task offloading for aerial edge internet of things (edgeiot),IEEE Internet of Things Journal 9 (2022) 21676–21686.
405. Courbon et al. [2010]J. Courbon, Y. Mezouar, N. Guénard, P. Martinet,Vision-based navigation of unmanned aerial vehicles,Control engineering practice 18 (2010) 789–799.
406. Liu et al. [2022]Z. Liu, H. Mao, C.-Y. Wu, C. Feichtenhofer, T. Darrell, S. Xie,A convnet for the 2020s,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 11976–11986.
407. Devlin [2018]J. Devlin,Bert: Pre-training of deep bidirectional transformers for language understanding,arXiv preprint arXiv:1810.04805 (2018).
408. De Curtò et al. [2023]J. De Curtò, I. De Zarza, C. T. Calafate,Semantic scene understanding with large language models on unmanned aerial vehicles,Drones 7 (2023) 114.
409. Wang et al. [2023]C. Wang, Z. Zhong, X. Xiang, Y. Zhu, L. Wu, D. Yin, J. Li,Uav path planning in multi-task environments with risks through natural language understanding,Drones 7 (2023) 147.
410. Kuwertz et al. [2018]A. Kuwertz, D. Mühlenberg, J. Sander, W. Müller,Applying knowledge-based reasoning for information fusion in intelligence, surveillance, and reconnaissance,in: Multisensor Fusion and Integration in the Wake of Big Data, Deep Learning and Cyber Physical System: An Edition of the Selected Papers from the 2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2017), Springer, 2018, pp. 119–139.
411. Feng et al. [2023]Y. Feng, H. Snoussi, J. Teng, A. Cherouat, T. Wang,Large language model-based multi-task uavs-towards distilled real-time interactive control,in: IET Conference Proceedings CP870, volume 2023, IET, 2023, pp. 114–118.
412. Mahajan et al. [2023]V. Mahajan, E. Barmpounakis, M. R. Alam, N. Geroliminis, C. Antoniou,Treating noise and anomalies in vehicle trajectories from an experiment with a swarm of drones,IEEE Transactions on Intelligent Transportation Systems 24 (2023) 9055–9067.
413. Telikani et al. [2024]A. Telikani, A. Sarkar, B. Du, J. Shen,Machine learning for uav-aided its: A review with comparative study,IEEE Transactions on Intelligent Transportation Systems (2024).
414. Bisio et al. [2022]I. Bisio, C. Garibotto, H. Haleem, F. Lavagetto, A. Sciarrone,A systematic review of drone based road traffic monitoring system,Ieee Access 10 (2022) 101537–101555.
415. Saputro et al. [2018]N. Saputro, K. Akkaya, R. Algin, S. Uluagac,Drone-assisted multi-purpose roadside units for intelligent transportation systems,in: 2018 IEEE 88th Vehicular Technology Conference (VTC-Fall), IEEE, 2018, pp. 1–5.
416. Dung [2019]N. D. Dung,Developing models for managing drones in the transportation system in smart cities,Electrical, Control and Communication Engineering 15 (2019) 71–78.
417. Menouar et al. [2017]H. Menouar, I. Guvenc, K. Akkaya, A. S. Uluagac, A. Kadri, A. Tuncer,Uav-enabled intelligent transportation systems for the smart city: Applications and challenges,IEEE Communications Magazine 55 (2017) 22–28.
418. Wang et al. [2023]L. Wang, X. Deng, J. Gui, P. Jiang, F. Zeng, S. Wan,A review of urban air mobility-enabled intelligent transportation systems: Mechanisms, applications and challenges,Journal of Systems Architecture 141 (2023) 102902.
419. Yao et al. [2024]J. Yao, J. Li, Y. Li, M. Zhang, C. Zuo, S. Dong, Z. Dai,A vision–language model-based traffic sign detection method for high-resolution drone images: A case study in guyuan, china,Sensors 24 (2024) 5800.
420. Yuan et al. [2024]Z. Yuan, F. Xie, T. Ji,Patrol agent: An autonomous uav framework for urban patrol using on board vision language model and on cloud large language model,in: 2024 6th International Conference on Robotics and Computer Vision (ICRCV), IEEE, 2024, pp. 237–242.
421. Zhu et al. [2024]H. Zhu, S. Qin, M. Su, C. Lin, A. Li, J. Gao,Harnessing large vision and language models in agriculture: A review,arXiv preprint arXiv:2407.19679 (2024).
422. Tian et al. [2024]Y. Tian, F. Lin, X. Zhang, J. Ge, Y. Wang, X. Dai, Y. Lv, F.-Y. Wang,Logisticsvista: 3d terminal delivery services with uavs, ugvs and usvs based on foundation models and scenarios engineering,IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI) (2024).
423. Jiang et al. [2024]H. Jiang, T. Wu, X. Ren, L. Gou,Optimisation of multi-type logistics uav scheduling under high demand,Promet-Traffic&Transportation 36 (2024) 115–131.
424. Huang et al. [2020]H. Huang, A. V. Savkin, C. Huang,Scheduling of a parcel delivery system consisting of an aerial drone interacting with public transportation vehicles,Sensors 20 (2020) 2045.
425. Wandelt et al. [2023]S. Wandelt, S. Wang, C. Zheng, X. Sun,Aerial: A meta review and discussion of challenges toward unmanned aerial vehicle operations in logistics, mobility, and monitoring,IEEE Transactions on Intelligent Transportation Systems (2023).
426. Luo et al. [2024]S. Luo, Y. Yao, H. Zhao, L. Song,A language model-based fine-grained address resolution framework in uav delivery system,IEEE Journal of Selected Topics in Signal Processing (2024).
427. Dong et al. [2024]C. Dong, N. Syed, F. Jiang, R. Elphick-Darling, S. Chen, J. Zhang, M. Lu, X. Liu,Securing uav delivery systems with blockchain and large language models: an innovative logistics solution,in: 2024 11th International Conference on Machine Intelligence Theory and Applications (MiTA), IEEE, 2024, pp. 1–8.
428. Jin et al. [2020]W. Jin, J. Yang, Y. Fang, W. Feng,Research on application and deployment of uav in emergency response,in: 2020 IEEE 10th International Conference on Electronics Information and Emergency Communication (ICEIEC), IEEE, 2020, pp. 277–280.
429. Goecks and Waytowich [2023]V. G. Goecks, N. R. Waytowich,Disasterresponsegpt: Large language models for accelerated plan of action development in disaster response scenarios,arXiv preprint arXiv:2306.17271 (2023).
430. Fourati and Alouini [2021]F. Fourati, M.-S. Alouini,Artificial intelligence for satellite communication: A review,Intelligent and Converged Networks 2 (2021) 213–243.
431. Wang et al. [2024]Y. Wang, J. Farooq, H. Ghazzai, G. Setti,Multi-uav placement for integrated access and backhauling using llm-driven optimization (2024).
432. Gong et al. [2024]Z. Gong, Z. Wei, D. Wang, X. Ma, H. Chen, Y. Jia, Y. Deng, Z. Ji, X. Zhu, N. Yokoya, J. Zhang, B. Du, L. Zhang,Crossearth: Geospatial vision foundation model for domain generalizable remote sensing semantic segmentation,arXiv preprint arXiv:2410.22629 (2024).
433. Hong et al. [2023]Y. Hong, H. Zhen, P. Chen, S. Zheng, Y. Du, Z. Chen, C. Gan,3d-llm: Injecting the 3d world into large language models,Advances in Neural Information Processing Systems 36 (2023) 20482–20494.
434. Zhang et al. [2024]S. Zhang, D. Huang, J. Deng, S. Tang, W. Ouyang, T. He, Y. Zhang,Agent3d-zero: An agent for zero-shot 3d understanding,arXiv preprint arXiv:2403.11835 (2024).
435. Hu et al. [2021]E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chen,Lora: Low-rank adaptation of large language models,arXiv preprint arXiv:2106.09685 (2021).
436. Casper et al. [2023]S. Casper, X. Davies, C. Shi, T. K. Gilbert, J. Scheurer, J. Rando, R. Freedman, T. Korbak, D. Lindner, P. Freire, et al.,Open problems and fundamental limitations of reinforcement learning from human feedback,arXiv preprint arXiv:2307.15217 (2023).
437. Chen et al. [2024]B. Chen, Z. Xu, S. Kirmani, B. Ichter, D. Sadigh, L. Guibas, F. Xia,Spatialvlm: Endowing vision-language models with spatial reasoning capabilities,in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 14455–14465.
